{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "020164e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "061d5afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv(r\"C:\\Users\\Aditya Singh\\Downloads\\archive (1)\\Iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e724b359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dc6a286",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.drop('Species',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c9ff16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c27d92d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = iris['Species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cfbb369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62541e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d5f8f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "527bec38",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1386ea22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec225ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f795040",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2b80831",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1bbacc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b350002c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ed13804",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_train = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c92e3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b5f474f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e2996dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=4,activation='relu',input_shape=[5,]))\n",
    "\n",
    "# Last layer for multi-class classification of 3 species\n",
    "model.add(Dense(units=3,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "539195fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "706ee1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9b0d16ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "4/4 [==============================] - 1s 60ms/step - loss: 1.0797 - accuracy: 0.3167 - val_loss: 1.0268 - val_accuracy: 0.4000\n",
      "Epoch 2/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.0712 - accuracy: 0.3167 - val_loss: 1.0242 - val_accuracy: 0.4000\n",
      "Epoch 3/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.0662 - accuracy: 0.3167 - val_loss: 1.0219 - val_accuracy: 0.4000\n",
      "Epoch 4/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.0590 - accuracy: 0.3167 - val_loss: 1.0196 - val_accuracy: 0.4000\n",
      "Epoch 5/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.0534 - accuracy: 0.3167 - val_loss: 1.0177 - val_accuracy: 0.4000\n",
      "Epoch 6/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.0481 - accuracy: 0.3167 - val_loss: 1.0161 - val_accuracy: 0.4000\n",
      "Epoch 7/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.0427 - accuracy: 0.3167 - val_loss: 1.0148 - val_accuracy: 0.4000\n",
      "Epoch 8/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.0380 - accuracy: 0.3167 - val_loss: 1.0133 - val_accuracy: 0.4000\n",
      "Epoch 9/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.0327 - accuracy: 0.3167 - val_loss: 1.0116 - val_accuracy: 0.4000\n",
      "Epoch 10/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.0282 - accuracy: 0.3167 - val_loss: 1.0098 - val_accuracy: 0.4000\n",
      "Epoch 11/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.0239 - accuracy: 0.3167 - val_loss: 1.0083 - val_accuracy: 0.4000\n",
      "Epoch 12/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.0196 - accuracy: 0.3167 - val_loss: 1.0067 - val_accuracy: 0.4000\n",
      "Epoch 13/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.0153 - accuracy: 0.3167 - val_loss: 1.0053 - val_accuracy: 0.4000\n",
      "Epoch 14/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.0118 - accuracy: 0.3000 - val_loss: 1.0037 - val_accuracy: 0.3667\n",
      "Epoch 15/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.0073 - accuracy: 0.3083 - val_loss: 1.0017 - val_accuracy: 0.3333\n",
      "Epoch 16/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.0037 - accuracy: 0.3000 - val_loss: 0.9996 - val_accuracy: 0.3000\n",
      "Epoch 17/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.9997 - accuracy: 0.3000 - val_loss: 0.9973 - val_accuracy: 0.3000\n",
      "Epoch 18/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.9960 - accuracy: 0.2917 - val_loss: 0.9948 - val_accuracy: 0.3000\n",
      "Epoch 19/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.9924 - accuracy: 0.2917 - val_loss: 0.9925 - val_accuracy: 0.3000\n",
      "Epoch 20/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.9885 - accuracy: 0.2833 - val_loss: 0.9900 - val_accuracy: 0.3333\n",
      "Epoch 21/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.9844 - accuracy: 0.2833 - val_loss: 0.9873 - val_accuracy: 0.3333\n",
      "Epoch 22/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.9807 - accuracy: 0.2917 - val_loss: 0.9847 - val_accuracy: 0.3333\n",
      "Epoch 23/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.9765 - accuracy: 0.3167 - val_loss: 0.9820 - val_accuracy: 0.3333\n",
      "Epoch 24/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.9728 - accuracy: 0.3250 - val_loss: 0.9790 - val_accuracy: 0.3667\n",
      "Epoch 25/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.9688 - accuracy: 0.3500 - val_loss: 0.9762 - val_accuracy: 0.3667\n",
      "Epoch 26/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.9648 - accuracy: 0.3583 - val_loss: 0.9731 - val_accuracy: 0.3667\n",
      "Epoch 27/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.9607 - accuracy: 0.3833 - val_loss: 0.9698 - val_accuracy: 0.3667\n",
      "Epoch 28/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.9566 - accuracy: 0.4000 - val_loss: 0.9665 - val_accuracy: 0.4000\n",
      "Epoch 29/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.9527 - accuracy: 0.4167 - val_loss: 0.9633 - val_accuracy: 0.3667\n",
      "Epoch 30/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.9482 - accuracy: 0.4500 - val_loss: 0.9597 - val_accuracy: 0.3667\n",
      "Epoch 31/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.9439 - accuracy: 0.4750 - val_loss: 0.9560 - val_accuracy: 0.3667\n",
      "Epoch 32/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.9395 - accuracy: 0.5000 - val_loss: 0.9524 - val_accuracy: 0.4000\n",
      "Epoch 33/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.9352 - accuracy: 0.5250 - val_loss: 0.9489 - val_accuracy: 0.4333\n",
      "Epoch 34/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.9307 - accuracy: 0.5250 - val_loss: 0.9451 - val_accuracy: 0.4333\n",
      "Epoch 35/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.9262 - accuracy: 0.5333 - val_loss: 0.9410 - val_accuracy: 0.4667\n",
      "Epoch 36/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.9217 - accuracy: 0.5750 - val_loss: 0.9372 - val_accuracy: 0.5000\n",
      "Epoch 37/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.9171 - accuracy: 0.5917 - val_loss: 0.9333 - val_accuracy: 0.5667\n",
      "Epoch 38/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.9125 - accuracy: 0.6000 - val_loss: 0.9294 - val_accuracy: 0.6000\n",
      "Epoch 39/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.9080 - accuracy: 0.5917 - val_loss: 0.9254 - val_accuracy: 0.6333\n",
      "Epoch 40/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.9033 - accuracy: 0.6167 - val_loss: 0.9213 - val_accuracy: 0.6333\n",
      "Epoch 41/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8987 - accuracy: 0.6250 - val_loss: 0.9171 - val_accuracy: 0.6333\n",
      "Epoch 42/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8942 - accuracy: 0.6500 - val_loss: 0.9128 - val_accuracy: 0.6667\n",
      "Epoch 43/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8899 - accuracy: 0.6583 - val_loss: 0.9088 - val_accuracy: 0.7000\n",
      "Epoch 44/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8851 - accuracy: 0.6833 - val_loss: 0.9046 - val_accuracy: 0.7000\n",
      "Epoch 45/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8806 - accuracy: 0.6833 - val_loss: 0.9003 - val_accuracy: 0.7000\n",
      "Epoch 46/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8759 - accuracy: 0.7167 - val_loss: 0.8959 - val_accuracy: 0.6667\n",
      "Epoch 47/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8712 - accuracy: 0.7167 - val_loss: 0.8917 - val_accuracy: 0.6667\n",
      "Epoch 48/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8664 - accuracy: 0.7000 - val_loss: 0.8875 - val_accuracy: 0.6000\n",
      "Epoch 49/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8619 - accuracy: 0.7000 - val_loss: 0.8833 - val_accuracy: 0.6667\n",
      "Epoch 50/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8570 - accuracy: 0.6917 - val_loss: 0.8790 - val_accuracy: 0.6667\n",
      "Epoch 51/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8526 - accuracy: 0.7000 - val_loss: 0.8748 - val_accuracy: 0.7000\n",
      "Epoch 52/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8474 - accuracy: 0.7083 - val_loss: 0.8705 - val_accuracy: 0.7000\n",
      "Epoch 53/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8426 - accuracy: 0.7167 - val_loss: 0.8661 - val_accuracy: 0.7000\n",
      "Epoch 54/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8381 - accuracy: 0.7167 - val_loss: 0.8617 - val_accuracy: 0.7000\n",
      "Epoch 55/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8332 - accuracy: 0.7167 - val_loss: 0.8574 - val_accuracy: 0.7000\n",
      "Epoch 56/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8283 - accuracy: 0.7083 - val_loss: 0.8528 - val_accuracy: 0.7333\n",
      "Epoch 57/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8236 - accuracy: 0.7083 - val_loss: 0.8482 - val_accuracy: 0.7333\n",
      "Epoch 58/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8188 - accuracy: 0.7000 - val_loss: 0.8442 - val_accuracy: 0.7333\n",
      "Epoch 59/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8141 - accuracy: 0.7083 - val_loss: 0.8403 - val_accuracy: 0.7000\n",
      "Epoch 60/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8093 - accuracy: 0.7250 - val_loss: 0.8363 - val_accuracy: 0.6667\n",
      "Epoch 61/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8047 - accuracy: 0.7333 - val_loss: 0.8323 - val_accuracy: 0.7000\n",
      "Epoch 62/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7998 - accuracy: 0.7333 - val_loss: 0.8282 - val_accuracy: 0.7000\n",
      "Epoch 63/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7953 - accuracy: 0.7417 - val_loss: 0.8244 - val_accuracy: 0.6667\n",
      "Epoch 64/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7906 - accuracy: 0.7417 - val_loss: 0.8205 - val_accuracy: 0.6667\n",
      "Epoch 65/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7860 - accuracy: 0.7333 - val_loss: 0.8167 - val_accuracy: 0.6667\n",
      "Epoch 66/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7813 - accuracy: 0.7250 - val_loss: 0.8127 - val_accuracy: 0.6667\n",
      "Epoch 67/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7767 - accuracy: 0.7250 - val_loss: 0.8084 - val_accuracy: 0.6333\n",
      "Epoch 68/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7723 - accuracy: 0.7250 - val_loss: 0.8044 - val_accuracy: 0.6333\n",
      "Epoch 69/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7676 - accuracy: 0.7167 - val_loss: 0.8001 - val_accuracy: 0.6333\n",
      "Epoch 70/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7630 - accuracy: 0.7250 - val_loss: 0.7959 - val_accuracy: 0.6333\n",
      "Epoch 71/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7587 - accuracy: 0.7167 - val_loss: 0.7919 - val_accuracy: 0.6000\n",
      "Epoch 72/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7543 - accuracy: 0.7000 - val_loss: 0.7880 - val_accuracy: 0.6000\n",
      "Epoch 73/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7499 - accuracy: 0.7000 - val_loss: 0.7840 - val_accuracy: 0.6000\n",
      "Epoch 74/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7453 - accuracy: 0.7000 - val_loss: 0.7796 - val_accuracy: 0.6000\n",
      "Epoch 75/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7410 - accuracy: 0.7000 - val_loss: 0.7752 - val_accuracy: 0.6000\n",
      "Epoch 76/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7365 - accuracy: 0.7167 - val_loss: 0.7708 - val_accuracy: 0.6000\n",
      "Epoch 77/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7321 - accuracy: 0.7167 - val_loss: 0.7665 - val_accuracy: 0.6000\n",
      "Epoch 78/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7277 - accuracy: 0.7167 - val_loss: 0.7624 - val_accuracy: 0.6000\n",
      "Epoch 79/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7232 - accuracy: 0.7250 - val_loss: 0.7587 - val_accuracy: 0.6000\n",
      "Epoch 80/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7189 - accuracy: 0.7250 - val_loss: 0.7546 - val_accuracy: 0.6000\n",
      "Epoch 81/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7144 - accuracy: 0.7250 - val_loss: 0.7505 - val_accuracy: 0.6333\n",
      "Epoch 82/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7103 - accuracy: 0.7250 - val_loss: 0.7466 - val_accuracy: 0.6333\n",
      "Epoch 83/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7060 - accuracy: 0.7250 - val_loss: 0.7419 - val_accuracy: 0.6333\n",
      "Epoch 84/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7017 - accuracy: 0.7250 - val_loss: 0.7381 - val_accuracy: 0.6333\n",
      "Epoch 85/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6973 - accuracy: 0.7250 - val_loss: 0.7342 - val_accuracy: 0.6333\n",
      "Epoch 86/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6933 - accuracy: 0.7250 - val_loss: 0.7305 - val_accuracy: 0.6333\n",
      "Epoch 87/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6890 - accuracy: 0.7167 - val_loss: 0.7266 - val_accuracy: 0.6333\n",
      "Epoch 88/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6850 - accuracy: 0.7167 - val_loss: 0.7225 - val_accuracy: 0.6333\n",
      "Epoch 89/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6808 - accuracy: 0.7167 - val_loss: 0.7186 - val_accuracy: 0.6333\n",
      "Epoch 90/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6767 - accuracy: 0.7167 - val_loss: 0.7150 - val_accuracy: 0.6333\n",
      "Epoch 91/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6727 - accuracy: 0.7167 - val_loss: 0.7110 - val_accuracy: 0.6333\n",
      "Epoch 92/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6689 - accuracy: 0.7167 - val_loss: 0.7073 - val_accuracy: 0.6333\n",
      "Epoch 93/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6647 - accuracy: 0.7167 - val_loss: 0.7041 - val_accuracy: 0.6333\n",
      "Epoch 94/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6608 - accuracy: 0.7167 - val_loss: 0.7007 - val_accuracy: 0.6333\n",
      "Epoch 95/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6568 - accuracy: 0.7167 - val_loss: 0.6970 - val_accuracy: 0.6333\n",
      "Epoch 96/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6529 - accuracy: 0.7167 - val_loss: 0.6936 - val_accuracy: 0.6333\n",
      "Epoch 97/300\n",
      "4/4 [==============================] - 0s 113ms/step - loss: 0.6491 - accuracy: 0.7167 - val_loss: 0.6899 - val_accuracy: 0.6333\n",
      "Epoch 98/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6453 - accuracy: 0.7167 - val_loss: 0.6862 - val_accuracy: 0.6333\n",
      "Epoch 99/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6416 - accuracy: 0.7167 - val_loss: 0.6826 - val_accuracy: 0.6333\n",
      "Epoch 100/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6380 - accuracy: 0.7250 - val_loss: 0.6795 - val_accuracy: 0.6333\n",
      "Epoch 101/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6341 - accuracy: 0.7250 - val_loss: 0.6757 - val_accuracy: 0.6333\n",
      "Epoch 102/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6304 - accuracy: 0.7250 - val_loss: 0.6720 - val_accuracy: 0.6333\n",
      "Epoch 103/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6269 - accuracy: 0.7250 - val_loss: 0.6680 - val_accuracy: 0.6333\n",
      "Epoch 104/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6232 - accuracy: 0.7333 - val_loss: 0.6642 - val_accuracy: 0.6333\n",
      "Epoch 105/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6197 - accuracy: 0.7417 - val_loss: 0.6601 - val_accuracy: 0.6333\n",
      "Epoch 106/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6161 - accuracy: 0.7500 - val_loss: 0.6566 - val_accuracy: 0.6333\n",
      "Epoch 107/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6126 - accuracy: 0.7500 - val_loss: 0.6534 - val_accuracy: 0.6333\n",
      "Epoch 108/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6092 - accuracy: 0.7500 - val_loss: 0.6502 - val_accuracy: 0.6333\n",
      "Epoch 109/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6058 - accuracy: 0.7500 - val_loss: 0.6466 - val_accuracy: 0.6333\n",
      "Epoch 110/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6025 - accuracy: 0.7500 - val_loss: 0.6436 - val_accuracy: 0.6333\n",
      "Epoch 111/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5991 - accuracy: 0.7583 - val_loss: 0.6399 - val_accuracy: 0.6333\n",
      "Epoch 112/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5957 - accuracy: 0.7583 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 113/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5925 - accuracy: 0.7583 - val_loss: 0.6336 - val_accuracy: 0.6667\n",
      "Epoch 114/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5892 - accuracy: 0.7583 - val_loss: 0.6306 - val_accuracy: 0.6667\n",
      "Epoch 115/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5860 - accuracy: 0.7583 - val_loss: 0.6277 - val_accuracy: 0.6667\n",
      "Epoch 116/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5830 - accuracy: 0.7583 - val_loss: 0.6249 - val_accuracy: 0.6667\n",
      "Epoch 117/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5796 - accuracy: 0.7583 - val_loss: 0.6217 - val_accuracy: 0.6667\n",
      "Epoch 118/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5765 - accuracy: 0.7667 - val_loss: 0.6183 - val_accuracy: 0.6667\n",
      "Epoch 119/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5735 - accuracy: 0.7667 - val_loss: 0.6147 - val_accuracy: 0.6667\n",
      "Epoch 120/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5704 - accuracy: 0.7667 - val_loss: 0.6122 - val_accuracy: 0.6667\n",
      "Epoch 121/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5673 - accuracy: 0.7667 - val_loss: 0.6091 - val_accuracy: 0.6667\n",
      "Epoch 122/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5644 - accuracy: 0.7667 - val_loss: 0.6064 - val_accuracy: 0.6667\n",
      "Epoch 123/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5615 - accuracy: 0.7667 - val_loss: 0.6037 - val_accuracy: 0.6667\n",
      "Epoch 124/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5585 - accuracy: 0.7667 - val_loss: 0.6004 - val_accuracy: 0.6667\n",
      "Epoch 125/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5556 - accuracy: 0.7750 - val_loss: 0.5971 - val_accuracy: 0.6667\n",
      "Epoch 126/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5527 - accuracy: 0.7750 - val_loss: 0.5943 - val_accuracy: 0.6667\n",
      "Epoch 127/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5498 - accuracy: 0.7750 - val_loss: 0.5916 - val_accuracy: 0.6667\n",
      "Epoch 128/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5470 - accuracy: 0.7750 - val_loss: 0.5887 - val_accuracy: 0.6667\n",
      "Epoch 129/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5442 - accuracy: 0.7750 - val_loss: 0.5861 - val_accuracy: 0.6667\n",
      "Epoch 130/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5415 - accuracy: 0.7750 - val_loss: 0.5837 - val_accuracy: 0.6667\n",
      "Epoch 131/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5386 - accuracy: 0.7750 - val_loss: 0.5810 - val_accuracy: 0.6667\n",
      "Epoch 132/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5360 - accuracy: 0.7750 - val_loss: 0.5779 - val_accuracy: 0.6667\n",
      "Epoch 133/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5334 - accuracy: 0.7750 - val_loss: 0.5746 - val_accuracy: 0.6667\n",
      "Epoch 134/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5306 - accuracy: 0.7750 - val_loss: 0.5722 - val_accuracy: 0.6667\n",
      "Epoch 135/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5280 - accuracy: 0.7750 - val_loss: 0.5700 - val_accuracy: 0.6667\n",
      "Epoch 136/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5252 - accuracy: 0.7750 - val_loss: 0.5670 - val_accuracy: 0.6667\n",
      "Epoch 137/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5226 - accuracy: 0.7750 - val_loss: 0.5641 - val_accuracy: 0.6667\n",
      "Epoch 138/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5202 - accuracy: 0.7750 - val_loss: 0.5609 - val_accuracy: 0.6667\n",
      "Epoch 139/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5177 - accuracy: 0.7750 - val_loss: 0.5588 - val_accuracy: 0.6667\n",
      "Epoch 140/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5150 - accuracy: 0.7833 - val_loss: 0.5556 - val_accuracy: 0.6667\n",
      "Epoch 141/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5124 - accuracy: 0.7833 - val_loss: 0.5529 - val_accuracy: 0.6667\n",
      "Epoch 142/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5100 - accuracy: 0.7833 - val_loss: 0.5507 - val_accuracy: 0.6667\n",
      "Epoch 143/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5075 - accuracy: 0.7917 - val_loss: 0.5480 - val_accuracy: 0.7000\n",
      "Epoch 144/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5050 - accuracy: 0.8000 - val_loss: 0.5456 - val_accuracy: 0.7000\n",
      "Epoch 145/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5026 - accuracy: 0.8000 - val_loss: 0.5430 - val_accuracy: 0.7000\n",
      "Epoch 146/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5002 - accuracy: 0.8083 - val_loss: 0.5411 - val_accuracy: 0.7000\n",
      "Epoch 147/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4980 - accuracy: 0.8083 - val_loss: 0.5384 - val_accuracy: 0.7000\n",
      "Epoch 148/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4955 - accuracy: 0.8083 - val_loss: 0.5367 - val_accuracy: 0.7000\n",
      "Epoch 149/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4935 - accuracy: 0.8000 - val_loss: 0.5350 - val_accuracy: 0.7000\n",
      "Epoch 150/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4910 - accuracy: 0.8083 - val_loss: 0.5319 - val_accuracy: 0.7000\n",
      "Epoch 151/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4887 - accuracy: 0.8167 - val_loss: 0.5289 - val_accuracy: 0.7333\n",
      "Epoch 152/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4865 - accuracy: 0.8333 - val_loss: 0.5262 - val_accuracy: 0.7333\n",
      "Epoch 153/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4841 - accuracy: 0.8417 - val_loss: 0.5239 - val_accuracy: 0.7333\n",
      "Epoch 154/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4820 - accuracy: 0.8417 - val_loss: 0.5214 - val_accuracy: 0.7333\n",
      "Epoch 155/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4798 - accuracy: 0.8417 - val_loss: 0.5196 - val_accuracy: 0.7333\n",
      "Epoch 156/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4775 - accuracy: 0.8417 - val_loss: 0.5176 - val_accuracy: 0.7333\n",
      "Epoch 157/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4754 - accuracy: 0.8417 - val_loss: 0.5155 - val_accuracy: 0.7333\n",
      "Epoch 158/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4734 - accuracy: 0.8417 - val_loss: 0.5144 - val_accuracy: 0.7333\n",
      "Epoch 159/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4712 - accuracy: 0.8417 - val_loss: 0.5122 - val_accuracy: 0.7333\n",
      "Epoch 160/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4692 - accuracy: 0.8417 - val_loss: 0.5106 - val_accuracy: 0.7333\n",
      "Epoch 161/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4671 - accuracy: 0.8417 - val_loss: 0.5077 - val_accuracy: 0.7333\n",
      "Epoch 162/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4650 - accuracy: 0.8417 - val_loss: 0.5054 - val_accuracy: 0.7333\n",
      "Epoch 163/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4629 - accuracy: 0.8417 - val_loss: 0.5030 - val_accuracy: 0.7667\n",
      "Epoch 164/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4609 - accuracy: 0.8500 - val_loss: 0.5002 - val_accuracy: 0.7667\n",
      "Epoch 165/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4589 - accuracy: 0.8500 - val_loss: 0.4980 - val_accuracy: 0.8000\n",
      "Epoch 166/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4568 - accuracy: 0.8500 - val_loss: 0.4953 - val_accuracy: 0.8000\n",
      "Epoch 167/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4549 - accuracy: 0.8500 - val_loss: 0.4926 - val_accuracy: 0.8333\n",
      "Epoch 168/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4530 - accuracy: 0.8750 - val_loss: 0.4896 - val_accuracy: 0.8333\n",
      "Epoch 169/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4511 - accuracy: 0.8833 - val_loss: 0.4875 - val_accuracy: 0.8333\n",
      "Epoch 170/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4492 - accuracy: 0.8833 - val_loss: 0.4852 - val_accuracy: 0.8333\n",
      "Epoch 171/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4473 - accuracy: 0.8833 - val_loss: 0.4834 - val_accuracy: 0.8333\n",
      "Epoch 172/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4454 - accuracy: 0.8833 - val_loss: 0.4814 - val_accuracy: 0.8333\n",
      "Epoch 173/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4435 - accuracy: 0.8833 - val_loss: 0.4798 - val_accuracy: 0.8333\n",
      "Epoch 174/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4416 - accuracy: 0.8833 - val_loss: 0.4784 - val_accuracy: 0.8333\n",
      "Epoch 175/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4396 - accuracy: 0.8833 - val_loss: 0.4767 - val_accuracy: 0.8333\n",
      "Epoch 176/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4379 - accuracy: 0.8833 - val_loss: 0.4752 - val_accuracy: 0.8333\n",
      "Epoch 177/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4360 - accuracy: 0.8833 - val_loss: 0.4733 - val_accuracy: 0.8333\n",
      "Epoch 178/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4342 - accuracy: 0.8833 - val_loss: 0.4719 - val_accuracy: 0.8333\n",
      "Epoch 179/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4324 - accuracy: 0.8833 - val_loss: 0.4705 - val_accuracy: 0.8333\n",
      "Epoch 180/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4308 - accuracy: 0.8833 - val_loss: 0.4694 - val_accuracy: 0.8333\n",
      "Epoch 181/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4289 - accuracy: 0.8833 - val_loss: 0.4673 - val_accuracy: 0.8333\n",
      "Epoch 182/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4271 - accuracy: 0.8833 - val_loss: 0.4654 - val_accuracy: 0.8333\n",
      "Epoch 183/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4255 - accuracy: 0.8833 - val_loss: 0.4628 - val_accuracy: 0.8333\n",
      "Epoch 184/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4238 - accuracy: 0.8833 - val_loss: 0.4615 - val_accuracy: 0.8333\n",
      "Epoch 185/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4220 - accuracy: 0.8833 - val_loss: 0.4598 - val_accuracy: 0.8333\n",
      "Epoch 186/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4203 - accuracy: 0.8833 - val_loss: 0.4581 - val_accuracy: 0.8333\n",
      "Epoch 187/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4187 - accuracy: 0.8833 - val_loss: 0.4553 - val_accuracy: 0.8667\n",
      "Epoch 188/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4168 - accuracy: 0.8833 - val_loss: 0.4531 - val_accuracy: 0.8667\n",
      "Epoch 189/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4152 - accuracy: 0.8833 - val_loss: 0.4511 - val_accuracy: 0.8667\n",
      "Epoch 190/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4137 - accuracy: 0.8833 - val_loss: 0.4498 - val_accuracy: 0.8667\n",
      "Epoch 191/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4120 - accuracy: 0.8917 - val_loss: 0.4475 - val_accuracy: 0.8667\n",
      "Epoch 192/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4102 - accuracy: 0.8917 - val_loss: 0.4457 - val_accuracy: 0.8667\n",
      "Epoch 193/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4086 - accuracy: 0.8917 - val_loss: 0.4442 - val_accuracy: 0.8667\n",
      "Epoch 194/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4070 - accuracy: 0.8917 - val_loss: 0.4423 - val_accuracy: 0.8667\n",
      "Epoch 195/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4054 - accuracy: 0.9000 - val_loss: 0.4404 - val_accuracy: 0.8667\n",
      "Epoch 196/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4038 - accuracy: 0.9083 - val_loss: 0.4385 - val_accuracy: 0.8667\n",
      "Epoch 197/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4021 - accuracy: 0.9083 - val_loss: 0.4369 - val_accuracy: 0.8667\n",
      "Epoch 198/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4007 - accuracy: 0.9083 - val_loss: 0.4360 - val_accuracy: 0.8667\n",
      "Epoch 199/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3991 - accuracy: 0.9000 - val_loss: 0.4345 - val_accuracy: 0.8667\n",
      "Epoch 200/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3975 - accuracy: 0.9083 - val_loss: 0.4317 - val_accuracy: 0.8667\n",
      "Epoch 201/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3959 - accuracy: 0.9083 - val_loss: 0.4295 - val_accuracy: 0.8667\n",
      "Epoch 202/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3943 - accuracy: 0.9083 - val_loss: 0.4277 - val_accuracy: 0.9000\n",
      "Epoch 203/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3927 - accuracy: 0.9083 - val_loss: 0.4262 - val_accuracy: 0.9000\n",
      "Epoch 204/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3912 - accuracy: 0.9083 - val_loss: 0.4243 - val_accuracy: 0.9000\n",
      "Epoch 205/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3897 - accuracy: 0.9083 - val_loss: 0.4226 - val_accuracy: 0.9000\n",
      "Epoch 206/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3881 - accuracy: 0.9083 - val_loss: 0.4213 - val_accuracy: 0.9000\n",
      "Epoch 207/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3866 - accuracy: 0.9083 - val_loss: 0.4202 - val_accuracy: 0.9000\n",
      "Epoch 208/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3850 - accuracy: 0.9083 - val_loss: 0.4187 - val_accuracy: 0.9000\n",
      "Epoch 209/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3836 - accuracy: 0.9083 - val_loss: 0.4172 - val_accuracy: 0.9000\n",
      "Epoch 210/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3821 - accuracy: 0.9083 - val_loss: 0.4156 - val_accuracy: 0.9000\n",
      "Epoch 211/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3806 - accuracy: 0.9083 - val_loss: 0.4141 - val_accuracy: 0.9000\n",
      "Epoch 212/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3792 - accuracy: 0.9083 - val_loss: 0.4119 - val_accuracy: 0.9000\n",
      "Epoch 213/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3775 - accuracy: 0.9167 - val_loss: 0.4106 - val_accuracy: 0.9000\n",
      "Epoch 214/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3763 - accuracy: 0.9167 - val_loss: 0.4085 - val_accuracy: 0.9000\n",
      "Epoch 215/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3747 - accuracy: 0.9167 - val_loss: 0.4071 - val_accuracy: 0.9000\n",
      "Epoch 216/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3733 - accuracy: 0.9167 - val_loss: 0.4063 - val_accuracy: 0.9000\n",
      "Epoch 217/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3718 - accuracy: 0.9167 - val_loss: 0.4050 - val_accuracy: 0.9000\n",
      "Epoch 218/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3703 - accuracy: 0.9167 - val_loss: 0.4032 - val_accuracy: 0.9000\n",
      "Epoch 219/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3689 - accuracy: 0.9167 - val_loss: 0.4012 - val_accuracy: 0.9000\n",
      "Epoch 220/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3675 - accuracy: 0.9167 - val_loss: 0.3993 - val_accuracy: 0.9000\n",
      "Epoch 221/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3661 - accuracy: 0.9167 - val_loss: 0.3976 - val_accuracy: 0.9333\n",
      "Epoch 222/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3645 - accuracy: 0.9167 - val_loss: 0.3965 - val_accuracy: 0.9333\n",
      "Epoch 223/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3632 - accuracy: 0.9167 - val_loss: 0.3951 - val_accuracy: 0.9333\n",
      "Epoch 224/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3617 - accuracy: 0.9167 - val_loss: 0.3938 - val_accuracy: 0.9333\n",
      "Epoch 225/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3604 - accuracy: 0.9167 - val_loss: 0.3926 - val_accuracy: 0.9333\n",
      "Epoch 226/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3590 - accuracy: 0.9167 - val_loss: 0.3911 - val_accuracy: 0.9333\n",
      "Epoch 227/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3576 - accuracy: 0.9250 - val_loss: 0.3892 - val_accuracy: 0.9333\n",
      "Epoch 228/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3562 - accuracy: 0.9250 - val_loss: 0.3872 - val_accuracy: 0.9667\n",
      "Epoch 229/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3548 - accuracy: 0.9333 - val_loss: 0.3856 - val_accuracy: 0.9667\n",
      "Epoch 230/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3534 - accuracy: 0.9333 - val_loss: 0.3843 - val_accuracy: 0.9667\n",
      "Epoch 231/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3521 - accuracy: 0.9417 - val_loss: 0.3829 - val_accuracy: 0.9667\n",
      "Epoch 232/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3508 - accuracy: 0.9417 - val_loss: 0.3810 - val_accuracy: 0.9667\n",
      "Epoch 233/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3493 - accuracy: 0.9417 - val_loss: 0.3796 - val_accuracy: 0.9667\n",
      "Epoch 234/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3480 - accuracy: 0.9417 - val_loss: 0.3784 - val_accuracy: 0.9667\n",
      "Epoch 235/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3467 - accuracy: 0.9417 - val_loss: 0.3768 - val_accuracy: 0.9667\n",
      "Epoch 236/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3453 - accuracy: 0.9417 - val_loss: 0.3753 - val_accuracy: 0.9667\n",
      "Epoch 237/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3440 - accuracy: 0.9417 - val_loss: 0.3743 - val_accuracy: 0.9667\n",
      "Epoch 238/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3428 - accuracy: 0.9417 - val_loss: 0.3723 - val_accuracy: 0.9667\n",
      "Epoch 239/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3413 - accuracy: 0.9417 - val_loss: 0.3714 - val_accuracy: 0.9667\n",
      "Epoch 240/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3400 - accuracy: 0.9417 - val_loss: 0.3703 - val_accuracy: 0.9667\n",
      "Epoch 241/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3387 - accuracy: 0.9417 - val_loss: 0.3688 - val_accuracy: 0.9667\n",
      "Epoch 242/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3374 - accuracy: 0.9417 - val_loss: 0.3673 - val_accuracy: 0.9667\n",
      "Epoch 243/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3360 - accuracy: 0.9417 - val_loss: 0.3651 - val_accuracy: 0.9667\n",
      "Epoch 244/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3348 - accuracy: 0.9500 - val_loss: 0.3630 - val_accuracy: 0.9667\n",
      "Epoch 245/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3334 - accuracy: 0.9500 - val_loss: 0.3614 - val_accuracy: 0.9667\n",
      "Epoch 246/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3323 - accuracy: 0.9583 - val_loss: 0.3594 - val_accuracy: 0.9667\n",
      "Epoch 247/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3311 - accuracy: 0.9667 - val_loss: 0.3586 - val_accuracy: 0.9667\n",
      "Epoch 248/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3295 - accuracy: 0.9583 - val_loss: 0.3571 - val_accuracy: 0.9667\n",
      "Epoch 249/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3283 - accuracy: 0.9667 - val_loss: 0.3552 - val_accuracy: 0.9667\n",
      "Epoch 250/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3270 - accuracy: 0.9750 - val_loss: 0.3542 - val_accuracy: 0.9667\n",
      "Epoch 251/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3258 - accuracy: 0.9750 - val_loss: 0.3531 - val_accuracy: 0.9667\n",
      "Epoch 252/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3245 - accuracy: 0.9667 - val_loss: 0.3520 - val_accuracy: 0.9667\n",
      "Epoch 253/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3232 - accuracy: 0.9750 - val_loss: 0.3507 - val_accuracy: 0.9667\n",
      "Epoch 254/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3220 - accuracy: 0.9750 - val_loss: 0.3489 - val_accuracy: 0.9667\n",
      "Epoch 255/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3209 - accuracy: 0.9750 - val_loss: 0.3473 - val_accuracy: 0.9667\n",
      "Epoch 256/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3197 - accuracy: 0.9750 - val_loss: 0.3472 - val_accuracy: 0.9667\n",
      "Epoch 257/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3182 - accuracy: 0.9750 - val_loss: 0.3461 - val_accuracy: 0.9667\n",
      "Epoch 258/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3170 - accuracy: 0.9667 - val_loss: 0.3448 - val_accuracy: 0.9667\n",
      "Epoch 259/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3159 - accuracy: 0.9750 - val_loss: 0.3438 - val_accuracy: 0.9667\n",
      "Epoch 260/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3146 - accuracy: 0.9750 - val_loss: 0.3419 - val_accuracy: 0.9667\n",
      "Epoch 261/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3133 - accuracy: 0.9750 - val_loss: 0.3406 - val_accuracy: 0.9667\n",
      "Epoch 262/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3122 - accuracy: 0.9833 - val_loss: 0.3388 - val_accuracy: 0.9667\n",
      "Epoch 263/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3111 - accuracy: 0.9833 - val_loss: 0.3370 - val_accuracy: 0.9667\n",
      "Epoch 264/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3099 - accuracy: 0.9833 - val_loss: 0.3364 - val_accuracy: 0.9667\n",
      "Epoch 265/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3086 - accuracy: 0.9833 - val_loss: 0.3348 - val_accuracy: 0.9667\n",
      "Epoch 266/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3074 - accuracy: 0.9833 - val_loss: 0.3338 - val_accuracy: 0.9667\n",
      "Epoch 267/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3064 - accuracy: 0.9833 - val_loss: 0.3317 - val_accuracy: 0.9667\n",
      "Epoch 268/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3050 - accuracy: 0.9917 - val_loss: 0.3305 - val_accuracy: 0.9667\n",
      "Epoch 269/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3039 - accuracy: 0.9917 - val_loss: 0.3297 - val_accuracy: 0.9667\n",
      "Epoch 270/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3027 - accuracy: 0.9917 - val_loss: 0.3284 - val_accuracy: 0.9667\n",
      "Epoch 271/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3015 - accuracy: 0.9917 - val_loss: 0.3272 - val_accuracy: 0.9667\n",
      "Epoch 272/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3006 - accuracy: 0.9833 - val_loss: 0.3265 - val_accuracy: 0.9667\n",
      "Epoch 273/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2991 - accuracy: 0.9917 - val_loss: 0.3248 - val_accuracy: 0.9667\n",
      "Epoch 274/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2980 - accuracy: 0.9917 - val_loss: 0.3232 - val_accuracy: 0.9667\n",
      "Epoch 275/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2969 - accuracy: 0.9917 - val_loss: 0.3212 - val_accuracy: 0.9667\n",
      "Epoch 276/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2958 - accuracy: 0.9917 - val_loss: 0.3197 - val_accuracy: 0.9667\n",
      "Epoch 277/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2946 - accuracy: 0.9917 - val_loss: 0.3184 - val_accuracy: 0.9667\n",
      "Epoch 278/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2937 - accuracy: 0.9917 - val_loss: 0.3171 - val_accuracy: 0.9667\n",
      "Epoch 279/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2924 - accuracy: 0.9917 - val_loss: 0.3166 - val_accuracy: 0.9667\n",
      "Epoch 280/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2912 - accuracy: 0.9917 - val_loss: 0.3155 - val_accuracy: 0.9667\n",
      "Epoch 281/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2901 - accuracy: 0.9917 - val_loss: 0.3143 - val_accuracy: 0.9667\n",
      "Epoch 282/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2891 - accuracy: 0.9917 - val_loss: 0.3129 - val_accuracy: 0.9667\n",
      "Epoch 283/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2878 - accuracy: 0.9917 - val_loss: 0.3125 - val_accuracy: 0.9667\n",
      "Epoch 284/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2867 - accuracy: 0.9917 - val_loss: 0.3115 - val_accuracy: 0.9667\n",
      "Epoch 285/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2856 - accuracy: 0.9917 - val_loss: 0.3103 - val_accuracy: 0.9667\n",
      "Epoch 286/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2846 - accuracy: 0.9917 - val_loss: 0.3095 - val_accuracy: 0.9667\n",
      "Epoch 287/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2837 - accuracy: 0.9917 - val_loss: 0.3074 - val_accuracy: 0.9667\n",
      "Epoch 288/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2823 - accuracy: 0.9917 - val_loss: 0.3061 - val_accuracy: 0.9667\n",
      "Epoch 289/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2812 - accuracy: 0.9917 - val_loss: 0.3050 - val_accuracy: 0.9667\n",
      "Epoch 290/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2801 - accuracy: 0.9917 - val_loss: 0.3039 - val_accuracy: 0.9667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 291/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2791 - accuracy: 0.9917 - val_loss: 0.3032 - val_accuracy: 0.9667\n",
      "Epoch 292/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2782 - accuracy: 0.9917 - val_loss: 0.3026 - val_accuracy: 0.9667\n",
      "Epoch 293/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2769 - accuracy: 0.9917 - val_loss: 0.3014 - val_accuracy: 0.9667\n",
      "Epoch 294/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2758 - accuracy: 0.9917 - val_loss: 0.2998 - val_accuracy: 0.9667\n",
      "Epoch 295/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2748 - accuracy: 0.9917 - val_loss: 0.2979 - val_accuracy: 0.9667\n",
      "Epoch 296/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2737 - accuracy: 1.0000 - val_loss: 0.2964 - val_accuracy: 1.0000\n",
      "Epoch 297/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2726 - accuracy: 1.0000 - val_loss: 0.2950 - val_accuracy: 1.0000\n",
      "Epoch 298/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2715 - accuracy: 1.0000 - val_loss: 0.2937 - val_accuracy: 1.0000\n",
      "Epoch 299/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2706 - accuracy: 1.0000 - val_loss: 0.2924 - val_accuracy: 1.0000\n",
      "Epoch 300/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2694 - accuracy: 1.0000 - val_loss: 0.2916 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16741c6efa0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=scaled_X_train, \n",
    "          y=y_train, \n",
    "          epochs=300,\n",
    "          validation_data=(scaled_X_test, y_test), verbose=1 ,callbacks=[early_stop]         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5c5854a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4747ddab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.079743</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>1.026788</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.071245</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>1.024171</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.066215</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>1.021856</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.058987</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>1.019619</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.053418</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>1.017687</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>0.273671</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.296422</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>0.272648</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.295017</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>0.271538</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.293702</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0.270593</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.292419</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0.269441</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.291553</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  accuracy  val_loss  val_accuracy\n",
       "0    1.079743  0.316667  1.026788           0.4\n",
       "1    1.071245  0.316667  1.024171           0.4\n",
       "2    1.066215  0.316667  1.021856           0.4\n",
       "3    1.058987  0.316667  1.019619           0.4\n",
       "4    1.053418  0.316667  1.017687           0.4\n",
       "..        ...       ...       ...           ...\n",
       "295  0.273671  1.000000  0.296422           1.0\n",
       "296  0.272648  1.000000  0.295017           1.0\n",
       "297  0.271538  1.000000  0.293702           1.0\n",
       "298  0.270593  1.000000  0.292419           1.0\n",
       "299  0.269441  1.000000  0.291553           1.0\n",
       "\n",
       "[300 rows x 4 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4003dec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics[['loss','val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "409eacdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAy1ElEQVR4nO3deXxU9b3/8dcnk31fgSyEhEUQBAHDIlpBaBGtigsq1tuqVSm9aqve22q1dXnUtv7UeqtXC6Uu1GrLtSpKKRVFRdxQQHaQxQTIBmSf7Nt8f3+cSQghIZNkJjOTfJ6PRx4zc86ZM5+T0TfffM/3fI8YY1BKKeX/ArxdgFJKKffQQFdKqX5CA10ppfoJDXSllOonNNCVUqqfCPTWBycmJpqMjAxvfbxSSvmlLVu2FBtjkjpa57VAz8jIYPPmzd76eKWU8ksicrizddrlopRS/YQGulJK9RMa6Eop1U94rQ+9I42NjeTl5VFXV+ftUhQQGhpKWloaQUFB3i5FKeUCnwr0vLw8oqKiyMjIQES8Xc6AZoyhpKSEvLw8MjMzvV2OUsoFXXa5iMiLInJcRHZ1sl5E5BkROSgiO0Rkck+LqaurIyEhQcPcB4gICQkJ+teSUn7ElT705cC806y/GBjl/FkELOlNQRrmvkO/C6X8S5ddLsaYDSKScZpN5gMvG2se3o0iEisiycaYQncVqZRS/sgYwxdvPgNlJw8djxh1PuNnXuX2z3NHH3oqkNvmdZ5z2SmBLiKLsFrxpKenu+GjlVLKd20/kMP0nQ8C4DAn/uL9wtEIPhroHf1d3uFdM4wxy4BlAFlZWQP6zhpNTU0EBvrUOWml+r36pmb2Ha2k5b4+CZHBDIkO5eujlTQ73B9JKz/8golA/VUvETLhRICf6/ZPsrgjUfKAoW1epwEFbtiv11xxxRXk5uZSV1fHT3/6UxYtWsQ777zD/fffT3NzM4mJibz//vtUVVVx5513snnzZkSEhx56iKuvvprIyEiqqqoAeP3111m9ejXLly/npptuIj4+nq1btzJ58mSuu+467rrrLmprawkLC+Oll15i9OjRNDc3c++997J27VpEhNtuu42xY8fy7LPPsnLlSgDee+89lixZwptvvunNX5VSfuXXq/fwysYjra9DgwJYcE7aScvcaXbAQQiGkPi+6ZFwR6CvAu4QkRXANKDCHf3nj/xzN3sK7L0urq2xKdE8dNm4Lrd78cUXiY+Pp7a2lilTpjB//nxuu+02NmzYQGZmJqWlpQD8+te/JiYmhp07dwJQVlbW5b7379/PunXrsNls2O12NmzYQGBgIOvWreP+++/njTfeYNmyZeTk5LB161YCAwMpLS0lLi6O22+/naKiIpKSknjppZe4+eabe/cLUWoAKa1u4B+b85g3bgjXTkmjsq6Ju/5vG69sPMKMEQnc+i33D89NO3gANgPRKW7fd0e6DHQR+TswC0gUkTzgISAIwBizFFgDXAIcBGoAv0+ZZ555prUlnJuby7Jly7jgggtax2PHx8cDsG7dOlasWNH6vri4uC73fc0112Cz2QCoqKjgxhtv5MCBA4gIjY2NrftdvHhxa5dMy+d9//vf55VXXuHmm2/m888/5+WXX3bTESvVvzz7wQGWf3bopGX1TQ7qmxz819wzGDU4CoB/bi9g3d7j3Dl7FOeOSHB/Ifl2EBtEDnb/vjvgyiiX67tYb4Db3VaRkystaU9Yv34969at4/PPPyc8PJxZs2Zx9tlns2/fvlO2NcZ0OLSv7bL247gjIiJan//qV7/iwgsvZOXKlRw6dIhZs2addr8333wzl112GaGhoVxzzTXaB69UBypqG/nj+m8YkRTJhLSYk9aNHhLVGuYAD3x3LNOHJzB9eLxnirEXQFQyBNg8s/92NBHaqaioIC4ujvDwcL7++ms2btxIfX09H330ETk5Oa1dLvHx8cydO5dnn32WP/zhD4DV5RIXF8fgwYPZu3cvo0ePZuXKlURFRXX6WampqQAsX768dfncuXNZunQps2bNau1yiY+PJyUlhZSUFB599FHee+89T/8qlPIZf//yCNuOlHPZ2SkUVdWx8ZvSk9bPHJ1ESGAA7+4+Rm5ZDTUNzTx29XjGpcR0skdLZmIEt35ruOcKr8iDmFTP7b8dDfR25s2bx9KlS5kwYQKjR49m+vTpJCUlsWzZMq666iocDgeDBg3ivffe45e//CW33347Z511FjabjYceeoirrrqKxx57jEsvvZShQ4dy1llntZ4gbe/nP/85N954I0899RSzZ89uXX7rrbeyf/9+JkyYQFBQELfddht33HEHADfccANFRUWMHTu2T34fSnlbfnktv3xrFw5j2HCgiNLqBoIDA4gItuKrur6JNTsLCQkKoLahmajQIK6enNZlmPcJewEkT+izjxNjvDN6MCsry7S/wcXevXs588wzvVKPv7jjjjuYNGkSt9xyS598nn4nymUOB+Ssh4Yat+yu0F5HdGgQ/95VyLo9x1hwThqvbbYueXnk8nEkx4QBkFNcze/+vReAu759BmOTo93y+W7xxi0w5Va46Ddu26WIbDHGZHW0TlvofuScc84hIiKC3//+994uRalTHfkM/nql23aX7HxcACwIAnbAt4OdC985sV0msKxl+Qa3fbz7JI7qs4/SQPcjW7Zs8XYJSnWuNMd6vOENiBzUq129tjmP5Z/ltL5+6tqzGTMkmqqGJgIDAggNPHkaqtrGZgwQHtQ3Jx9dFhAISWP67OM00JVS7mHPBwQyL4DA4C4370xjs4OndhaRmDKBfUcrGZ8aw5hJ5wEQ2cl7wnr8af2LBrpSyj3s+VbLvBdhDrBmZyFH7XX89qqzCBBhaHy4mwrs/zTQlVLuYS/o1RWRxhge+ece/r2rkOFJEcw6YxABATqFc3foPUWVUu5RkQ/RPR9z/Xl2Ccs/O0RMWBD3zRujYd4D2kJXSrmHvcDqPweaHYa3tuZT3dDk8tvf3lZAfEQwq+44n1BfO7npJzTQe6HtrIpKDWj1lVBf0drlsnpHAf/1j+3d3s3PLhqtYd4LGuj9gM6trvpU5TFobjh5Wdkh6zE6lZKqep7/OIcRSRH834/O7fCGCR0JECE2PMidlQ44vpsC/74Pju507z6HjIeLH+t09b333suwYcP4z//8TwAefvhhRIQNGzZQVlZGY2Mjjz76KPPnz+/yo6qqqpg/f36H73v55Zd58sknEREmTJjAX//6V44dO8bixYvJzs4GYMmSJaSkpHDppZeya5d1f+4nn3ySqqoqHn74YWbNmsWMGTP49NNPufzyyznjjDN49NFHaWhoICEhgVdffZXBgwd3OGd7eXk5u3bt4n/+538A+POf/8zevXt56qmnevXrVQPA1/+CFd/rdPWe2lgueXQdAL+58iwSI0P6qjKFLwe6FyxcuJC77rqrNdBfe+013nnnHe6++26io6MpLi5m+vTpXH755V3eQDk0NJSVK1ee8r49e/bwm9/8hk8//ZTExMTWudV/8pOfMHPmTFauXElzczNVVVVdzq9eXl7ORx99BFgTg23cuBER4fnnn+fxxx/n97//fYdztgcHBzNhwgQef/xxgoKCeOmll/jTn/7U21+fGgiO7bYeL3sGpN2YipBInvoymoQIOw9eNpbvjk8+9f3Ko3w30E/TkvaUSZMmcfz4cQoKCigqKiIuLo7k5GTuvvtuNmzYQEBAAPn5+Rw7dowhQ4acdl/GGO6///5T3vfBBx+wYMECEhMTgRNznX/wwQet85vbbDZiYmK6DPTrrruu9XleXh7XXXcdhYWFNDQ0tM7d3tmc7bNnz2b16tWceeaZNDY2Mn78+G7+ttSAZM+HiCQ458aTFh8qruanK7ayPa+Yn84ZxfyJfTfDoDrBdwPdSxYsWMDrr7/O0aNHWbhwIa+++ipFRUVs2bKFoKAgMjIyTpnjvCOdva+zuc47EhgYiMPhaH19urnV77zzTu655x4uv/xy1q9fz8MPPwx0Prf6rbfeym9/+1vGjBmjdz5SrutkrPnSj77h66OVXDkplZtmZPR9XQrQQD/FwoULue222yguLuajjz7itddeY9CgQQQFBfHhhx9y+PBhl/ZTUVHR4fvmzJnDlVdeyd13301CQkLrXOdz5sxhyZIl3HXXXTQ3N1NdXc3gwYM5fvw4JSUlREZGsnr1aubNm9fp57XMrf6Xv/yldXlnc7ZPmzaN3NxcvvrqK3bs2NGL35jqT7KLqnjzq3xMx/d556b8bMpDknlr7dety4yBN7fmc/XkNH53lf6l500a6O2MGzeOyspKUlNTSU5O5oYbbuCyyy4jKyuLiRMnMmaMaxPtdPa+cePG8cADDzBz5kxsNhuTJk1i+fLlPP300yxatIgXXngBm83GkiVLOPfcc3nwwQeZNm0amZmZp/3shx9+mGuuuYbU1FSmT59OTo41sVFnc7YDXHvttWzbts2lW+epgeGhVbv5+EAxgZ1c1HNbUCEbK4fzp4+yT1oeERLokXtyqu7R+dAHsEsvvZS7776bOXPmdLqNfif+o6iyniOl1lzkIwdF4nAYsouru/X+xa9s4b/nnsEdszuY8rWhGn6bAnMegm/d466yVTf1ej50EZkHPA3YgOeNMY+1Wx8HvAiMAOqAHxpjdvWqauUx5eXlTJ06lbPPPvu0Ya78R1Ozgyv/+Cl5ZbUATM2Mp7Kuib2F9m7tJyzIxvemDet4pb3AeuzF5f3Ks7oMdBGxAc8B3wHygE0issoYs6fNZvcD24wxV4rIGOf2AyIpdu7cyfe///2TloWEhPDFF194qaKuxcbGsn//fm+Xodzo37uOkldWyy8uHkNRZT3Pf2J1uf1k9kjOyXD9BsipsWHER3QyW6I933rsw3tkqu5xpYU+FThojMkGEJEVwHygbaCPBX4HYIz5WkQyRGSwMeZYdwvqzigQXzB+/Hi2bdvm7TI8wlvdcap7jDE8/0kOGQnh3Pqt4dQ0NLFiUy6hQTZunz2SkPWPwpaXev9BTc6rQ3sxo6LyLFcCPRXIbfM6D5jWbpvtwFXAJyIyFRgGpAEnBbqILAIWAaSnp5/yQaGhoZSUlJCQkOBXod4fGWMoKSkhNDTU26WoLnx1pIztueU8cvk4bAFCVGgQTy+cSEigjZBAGxx8D0JjYNTc3n9Y5GCI05OfvsqVQO8oWds33R4DnhaRbcBOYCtwyjRrxphlwDKwToq2X5+WlkZeXh5FRUUulKU8LTQ0lLS0NG+XoTrw/MfZ7C2sBGBXfgXRoYEsOOfEdzXnzMEnNrYXwNj5cMkTfV2m6mOuBHoeMLTN6zSgoO0Gxhg7cDOAWE3rHOdPtwQFBbVe4aiU6tj+Y5U8+q+9JEQEt85M+NNvn0FESAf/OzfWQk2JdpMMEK4E+iZglIhkAvnAQuCk2XlEJBaoMcY0ALcCG5whr9SA1dTsYP2+IhqaHV1v3A0rt+YTEhjAe/fM7PwEZgsdmTKgdBnoxpgmEbkDWIs1bPFFY8xuEVnsXL8UOBN4WUSasU6W3uLBmpXyC69+cYSHVu32yL6/P31Y12EOGugDjEvj0I0xa4A17ZYtbfP8c6CDKxGUGpiaHYYXP83h7KGxPH71BLfuWwQyEyO63hA00AcYvfRfKQ/49GAxh0tq+PlFYxg9JMp7hdjzrEftQx8Q9CbRSnnAHucVmt86I9G7hdgLICwOgsO9W4fqE9pCV8oDcoqqSYwMITrUTbdUW/MzKO7B1b3H9mh3ywCiga6UB+QUVzPc1X7urtRVwJfLIHYYRJ3+xiqniM+Es652Tx3K52mgK+UBOSXVXDg6yT07azmxOedBGL/APftU/ZL2oSvlZpV1jRRV1pOZGOmeHbZMiqVdJ6oL2kJXyg2MMRRU1NHcbDhw3Lok3+WhhV1paaHrLIeqCxroSrnBK18c4VdvnXwLgJGD3NRCr8gHBKKS3bM/1W9poCvVS80Ow583ZDM2OZpbzrfmIoqLCHJfoNvzrVkObW4aMaP6LQ10pTrxf5uO8OePu55jrrHZwZHSGv54w2QuGe+BVrS9QC8MUi7RQFeqA3WNzTyxdh9RoUGMTY7ucvsLRw9i7tjBXW7XI/YCSBjhmX2rfkUDXakOrNpeQHFVA08vnMR5I7t5tWdNKWxcAs317imm7BAMn+mefal+TQNdqQ78e2chmYkRzBiR0P03f70aNjwOthBrJq3eEhukT+/9flS/p4GuVDvGGLbmlnPR2CE9uxViRR4gcH++nshUfUovLFKqnZziasprGpk8LLZnO7DnW5foa5irPqaBrlQ7Xx0pB2BSelzPdqCjUpSXaKAr1c6XOSVEhQYyMqmH48gr8jXQlVdooCvVRkVNI//cXshF44YQENDDE5r2AohOc29hSrnApZOiIjIPeBrrnqLPG2Mea7c+BngFSHfu80ljzEturlUpt1u9o4B1e44BMGNEIqU1DdQ2NvPD8zJ7tsM6OzRUagtdeUWXgS4iNuA54DtAHrBJRFYZY/a02ex2YI8x5jIRSQL2icirxpgGj1StlBtU1zfxizd3EiCCLUBYs+sosWFBnDcygbEpXV9M1KHWmRE10FXfc6XLZSpw0BiT7QzoFcD8dtsYIEqsMV6RQCnQ5NZKlXKjnOJqnli7j8q6Jl68aQqv/Wg6DU0OjlfWt87H0m2NtbBnlfVcp7pVXuBKl0sqkNvmdR4wrd02zwKrgAIgCrjOGONovyMRWQQsAkhPT+9JvUr1WrPD8IMXvyC3tJasYXGcM8wazTJ37GCOlNYw64xBPdvxzn/A+t9CQKBeqq+8wpVA7+jMkGn3+iJgGzAbGAG8JyIfG2PsJ73JmGXAMoCsrKz2+1CqT7y7+yi5pbX89srxXDHpRNfI/35vEs0O0/OToWWHrKs6794NkT38R0GpXnClyyUPGNrmdRpWS7ytm4E3jeUgkAOMcU+JSrnXC5/kMDQ+jOumDCU8+ESbJiTQdtLrbrMXWHOWd/e+n0q5iSuBvgkYJSKZIhIMLMTqXmnrCDAHQEQGA6OBbHcWqpQ7bMstZ/PhMm6ekYmtpy3xztjz9a5Cyqu6bI4YY5pE5A5gLdawxReNMbtFZLFz/VLg18ByEdmJ1UVzrzGm2IN1K9Utf1i3n43ZJeSV1RIVEsi1U4Z2/abuqsiH5Anu369SLnLp70tjzBpgTbtlS9s8LwDmurc0pdzjUHE1T79/gOGJEaTEhvGfs0YSGeLmeemMsbpcRl/s3v0q1Q0626LyC8YYVm7Np7S6+5c2fHKwmKCAAP6+aDqDokI9UB1QWwZNtTpcUXmVBrryC58eLOGe17b3+P03TEv3XJiD1ToHvaBIeZUGuvIphRW11DY0n7L8Txu+ITEyhPfuvoBAW/dPZrq9i6UtY+DoDut5jM7horxHA135jI3ZJSxctrHT9fd85wziIoL7sCIXbV8Bb/3Yeh7jgZOtSrlIA135jGUbskmMDOaX3x17yp3bAgMCmHOmj16sU7QXAoLgP96AKA/dKFopF2igqz61Pbecn72+nabmUy8Uzi6u5q5vj+KKSX52YrHlhhZ6I2flZRroqk/97wcHOFpRx8zRp7a2szLiuHlGDyfG8iZ7gY5uUT5BA115TG5pDa9sPEyzw2qNNzkM6/Ye5ydzRnHPd87wcnVuVJEHQ6d6uwqlNNCV5zy+dh+rdxQQHmRrXZYWF8b3pw/zYlVu5nBAZaEOV1Q+QQPdz2zPLafJYZicHou0P3PoQ/LLa1mzs5DbvjWc+y8509vleE5NCTQ3aJeL8gl6T1E/8uG+48x/7lOuXvIZK7fme7uc03r5s0MA3Dgjw6t1eJw9z3rUQFc+QAPdj/x5QzZDokMZNSiSP3+cgzG+OaV8dX0Tf/vyCPPOGkJqbJi3y/EsvUJU+RDtcvE1eVvg1auhqQFCo2HRR+ytCuM/nv+CkuoG7p03hrjwIO57cyefZ5cwY0Sitys+xT8251JZ18StPb2Vm7d98j/w0ROubetotB71ClHlAzTQfU3eJmuip7HzYc/bcGwXf9ocT11jM3fOHskPzh2GLUB4Yu0+Xvg4x+cCvdlheOmzQ0xOj2VSepy3y+mZ7I8gNAbOusq17WPT9Q5FyidooPsaez7YQuDbj8Cet6k4fpjVO+r5wbkZ/Nfc0a2b3TB9GM+8f4DbX/2K4MAAfjJnFCs2HeH6KelkJEZ0uvvnPjzI3kJ7p+svnZDMvLOSu1Xylzml/HXjYYwxVNY1cbikhp9f5Mc3rLIXQNo5cNFvvF2JUt2ige5r7PlWf6zzJFtuzgGaHINZOPXkOUJ+cO4wNuwvYu9RO7mlNWw6VEpeWS0F5XX87/WTOtz17oIKnli7j+SYUMKCbaesL61u4PNvSpg1ehChQaeu74gxhodX7eZIaQ2DokMAuHB0EheN89NL4I2xvoMRs71diVLdpoHeRypqGlm//zhpcWGcMyz+pHW1Dc2s23uMZodh1rHDxEanQmAwRAyipvgIMWFBjEyKPOk9iZEhvHX7eQA8+PYuXv78MABrdhZy38VjTjoZueVwKbmltby9LZ/wYBvv3HUBMWFBp9T42cFivvf8Fzyxdh/jU2NcOq6Cilr2FNp57KrxLJya3q3fiU+qt0NDlZ7kVH5JA72P/GnDN/xx/TcE2YStD849aTrXZz88wHMffgPAx8GHaRwxgySA6BSkqIBJ6bGnvRP9zedlsmJTLotnjuCZ9w+walsBP541ArBGnCxctpFG59wpt5yf2WGYA5w7IoHxqTG88ElOt45tUFSI/82/0hkdtaL8mAZ6H8ktqwWgsdmwI7ecGSOtk5m1Dc28+sURZo8ZxP0Xj2bIkjLeLQljTmMztsgUovJ3MrmLk4uZiRFseuDbRIcG8s/tBXx1pKx13fa8chqbDY8vmMDUjHiGxod3uh8R4f9+NJ1j9vpuHVt8RLDLXTQ+r8I5vl9HrSg/5FKgi8g84Gmsm0Q/b4x5rN36nwE3tNnnmUCSMabUjbX6tcLyWs5MjmZvoZ2tbQL9ja/yKK9pZPHMEYwMrwWa2FgSyt2PvMsbw6IYJiVMSo/tcv8tre5JQ2PZcKAYYwwiwtYj5QDMHTuY2PCu5xIPDw4kM3EA/ztvdwa6ttCVH+rywiIRsQHPARcDY4HrRWRs222MMU8YYyYaYyYCvwA+0jA/WWFFHWOGRDEiKYKvDlstaIfD8OKnOYxPjWFKRlzrVYcXTpmEAP86LERLDdNSXL+pw6RhcRRX1ZPn/Itg65EyhidFuBTmCmegC0R1b6SPUr7AlabYVOCgMSYbQERWAPOBPZ1sfz3wd/eU5+f2r4VPn8YYBz+qjuJozK+xBcSxekcBd63YysKhZTxa/gBnDApDXgqBunIAZk+dyFWOAAo2JwAQXLQLVj5l7fOKJacd8zzZ2Zq/9S+biQkLYkd+OZdO0NbmST5/Dvau7nhdaTZEDgZbx+cZlPJlrlz6nwrktnmd51x2ChEJB+YBb3SyfpGIbBaRzUVFRd2t1f/sfB0KttJcUcgPbO+SGhXA9VOHMi4lhre2FbB93d+YYdtDfFQ4BNggPAHGXQmDzuT2C0cycqRzitldb8DBddbPkc9P+5FjhkRz1eRU4iOCsQUIWcPiWThFb4t2ks0vQuk31u+8/U/iKJj2I29XqFSPuNJC72h4RWeTiFwGfNpZd4sxZhmwDCArK8s3JyJxJ3s+JE+kcNgVDP3456QH2Tln2Bm89qNzufDJ9cTYi6gOTyDiplNbi2lx8JMrZsIzQN6XbfZZcNqPtAUIT1070b3H0Z8YY534nHKLXjik+h1XWuh5QNsmXhrQWaosRLtbTnBeJHTUWOPOUwOsf+dsAcIdF45kWFA5IfGnaT23nJg7thtswdYVpHbfnmXR59WWQVOtnvRU/ZIrgb4JGCUimSISjBXaq9pvJCIxwEzgbfeW6KeMAXsBjqgUdlVFAZBkiltXXztlKOcm1hEYe5rhcYEhEJEExmFdORqTemJYneqZ1nHm/WTcvFJtdBnoxpgm4A5gLbAXeM0Ys1tEFovI4jabXgm8a4yp9kypfqa6GJobWH80iCc3VgEQWX/85G1cuRdlS0syOtX66aLLRXVBA131Yy4NODbGrAHWtFu2tN3r5cBydxXm95xdI3uqokhMSKC5IQpb2zCus1uXmXf1p390GhRut7YTgcOnPymqutB6QwrtclH9zwC+gsTDnOG9qyqSs9JisJWnndz/3RLuXV2R2BI8MamAQGUBOJqtERmq++wFIDaIGuLtSpRyO71jkac4w3trRQSZiRFWMJ8U6C5ekXhSl0sKOJqgegAM+fQUe4EV5voPouqHtIXuKfZ8TEAgxx1RVqDXp0Lul7DpBRg5B75w9lh11Zfb0oKPTrW6XADe/aU1Zj0wBM67C8LjO327T6ophU//AE3dmzPGLQ59rP3nqt/SQPcUewF1oYMxNQHWDSeCZ8JXL8O/7oGZ98GBd2HwWV230NOmWNulTLJGu8QMtd5rjNUHnzQGJn6vb47JXb7+F3z6NIREn/hHqi+d7We/L6VcpIHuKRX5VARZl+gPT4yAYQug6jis/YV1Yi4oHH78adf7ic88ebu7d1mPjXXwm8H+OS695fzBzw5af2UopdxC+9A9xZ5PbnMsCRHBxEU4J8YKjXauK7Bap70RFArhif45Lt2eBxGDNMyVcjMNdE8wBmMvYFtFBAvOaTOKJcS6wMgK9Kjef050in+OS7cX6LBBpTxAA90TakqQ5noKTQI3zsg4sdztgZ7qn10uFfl6AwmlPEAD3ROcIWuLTSWlzb09W7tZ6u1ubKH7YaBrC10pj9BA9wRnN0hwXLtWaNsQd0egx6Rak0011PR+X32lvhLqKzTQlfIADXQPaCqzpo+PHpxx8oqTAr2XJ0XhxHhqf+pHb51LRbtclHI3HbboThV5kLOBun3rCDE2BqV4uIXe0srd9qp1Y4aAIBhzCQRHdP3e/K+g6Ove19BdxfutR22hK+V2Guju9N6DsOsNIoG9Jp2MxHat8OBIrPuFmBNDGHsjYRQEBMInT51Y9t2nrJs3dOXv10PV0d7X0BMBQZAw0jufrVQ/poHuTmWHIX0GK1Lv55EPj/N5YruWsojV1VJf4aYWejL89wHrJKsx8NxUKD/c9fsa66wwn3EnTLm193V0V0i0/01XoJQf0EB3J3sBjJjNxrJIwiLqiA0PPnWbkCj3BTpYwdgSjlHJrvWnVzq3GTQW4jLcU4dSyuv0pKi7NDdB1VFqQgexZtdRLj6rk+lZW4LcHSdF24tJcy3QK1yc6VEp5Vc00N2l6igYBxuLw2hocvDD8zM73q410N3UQm/L1XHpOtJEqX5JA91dnCG5pTyMcSnRjEiK7Hg7jwd6ATgcp9+udS72ZPfXoJTyGpcCXUTmicg+ETkoIvd1ss0sEdkmIrtF5CP3lukHKqxbm+2qiuw8zMHDgZ4GzQ1QU3L67ez5EBrr2vBGpZTf6DLQRcQGPAdcDIwFrheRse22iQX+CFxujBkHXOP+Un2cs4W+tSLCmv+8My3DFT3Rh97SJ95Vt4srN6dWSvkdV0a5TAUOGmOyAURkBTAf2NNmm+8BbxpjjgAYY46fspd+rqk8DwkMx14Xbs1/3pmWIPdUlwtYd0ayBXW+XWkOxA51/+crpbzKlUBPBXLbvM4DprXb5gwgSETWA1HA08aYl91SoZ/Ytns3cQ0xgFi3nOtM5GDr5haeCPTYYYDAv3/W9baZ33L/5yulvMqVQO/oHmGmg/2cA8wBwoDPRWSjMWb/STsSWQQsAkhPT+9+tT7q4PFKAioLKDAJAKfvcplyC4yae/oWdE9FJMAP17pwBahAxvnu/3yllFe5Euh5QNu/z9OA9oOd84BiY0w1UC0iG4CzgZMC3RizDFgGkJWV1f4fBb/18ueH+bGU8onjLABiwk4T1sERMGiM54pJb//Hk1JqoHBllMsmYJSIZIpIMLAQWNVum7eBb4lIoIiEY3XJ7HVvqb7rs/3HGCzlTJ84nqcXTvR2OUqpAarLFroxpklE7gDWAjbgRWPMbhFZ7Fy/1BizV0TeAXYADuB5Y8wuTxbuK8qqG6gqyScg1MHQjFEMnaijR5RS3uHSXC7GmDXAmnbLlrZ7/QTwhPtK8w/bcstJllLrhQ4FVEp5kV4p2ktfHSkjJcB5IY/OjaKU8iIN9F7aXWBnQlS19UIDXSnlRTp9bi8dr6wjI6gcmsMhLM7b5SilBjBtofdSSVUDQ6TUmotcOhqyr5RSfUMDvReMMZRUNRBNNYQneLscpdQAp4HeC/baJhqaHURQ45lL+ZVSqhs00HuhqKoegDCHBrpSyvs00HuhxBnowc3VJ6bFVUopL9FA74XiqgYAghorPTO/uVJKdYMGei8UV9UTgIOAJu1yUUp5nwZ6L5RU1RMltdYLDXSllJdpoPdCUVUDaeFN1gsNdKWUl2mg90JRZR1p4c3WCw10pZSXaaD3UFl1A58cLGZikvPqUD0pqpTyMp3LpQe2HC5l2YZs6hodXDYmCrLRQFdKeZ0Geg88tGo3u/LtXDJ+CGnhh6yF2uWilPIy7XLpJmMM2UXV3DQjg+e+NxnqK60VGuhKKS/TQO+mosp6ahqaGZ4UgYhooCulfIYGejdlF1s3s8hMjLAW1NkBgeBI7xWllFK4GOgiMk9E9onIQRG5r4P1s0SkQkS2OX8edH+pviHHGegZCc5Ar6+0WucB+m+jUsq7ujwpKiI24DngO0AesElEVhlj9rTb9GNjzKUeqNGn5BRXExwYQEpsmLWgJdCVUsrLXGlWTgUOGmOyjTENwApgvmfL8l3ZRdVkJIRjC3COP6+3a6ArpXyCK4GeCuS2eZ3nXNbeuSKyXUT+LSLjOtqRiCwSkc0isrmoqKgH5XrfoZLqE/3nADWlei9RpZRPcCXQO7pRpmn3+itgmDHmbOB/gbc62pExZpkxJssYk5WUlNStQn1Bs8NwuKSajLaBbs+H6I7+fVNKqb7lSqDnAUPbvE4DCtpuYIyxG2OqnM/XAEEikui2Kn1Eflktjc2G4S2BbgzYCyA6xbuFKaUUrgX6JmCUiGSKSDCwEFjVdgMRGSJi3fJeRKY691vi7mK9Lbu4CoDMROcQxZoSaK7XFrpSyid0OcrFGNMkIncAawEb8KIxZreILHauXwosAH4sIk1ALbDQGNO+W8bvHWo/Bt2ebz3GaKArpbzPpblcnN0oa9otW9rm+bPAs+4tzffkFFcTFRJIYmSwtaDCGeja5aKU8gF6NUw3ZBdbJ0SdvUsnWuja5aKU8gEa6N2QU9xuyKK9AAICIWKQ94pSSiknDXQX1Tc1k19e2y7Q8yEqRS/7V0r5BE0iFx0pqcEYGJ7UroWuJ0SVUj5CA91Fp8yyCM6LivSEqFLKN2igu6h1lkW9qEgp5aM00F2UU1RNYmQw0aFB1oKaUmiqg+g07xamlFJOGuguymk/KZddx6ArpXyLBrqL8stqGRoXfmKB3TmdjY5BV0r5CA10FzQ7DMfsdSTHhp5YaM+zHnWUi1LKR2igu6C4qp4mh2FITNiJha0XFfnfNMBKqf5JA90FhRV1AKTEOFvodRVwbDdEJUOAzYuVKaXUCRroLigsrwVgSEug/+Nm2P8OxGV4ryillGpHA90FLS305JYul5IDkDkTrlrmxaqUUupkGuguOGqvIyQwgLjwIHA4wF4IqZN1yKJSyqdooLugoLyW5JhQa9rc6iJwNOpwRaWUz9FAd8HRiroT3S16QZFSykdpoHfBGMPBoiqGJTgvKtILipRSPkoDvQvZxdWU1zQyKT3WWqB3KVJK+SiXAl1E5onIPhE5KCL3nWa7KSLSLCIL3Feid209Ug7A5PQ4a4E9H2zBEJ7gvaKUUqoDXd4kWkRswHPAd4A8YJOIrDLG7Olgu/8HrPVEoa2MAePo5pukx3cV+upIGVGhgYxIirQW2AucFxTpHzdKKd/SZaADU4GDxphsABFZAcwH9rTb7k7gDWCKWytsb89b8I+buveegED4jzdg+Kxuf9wle37GOdGjCAi4yFpQkQ8xOmWuUsr3uBLoqUBum9d5wLS2G4hIKnAlMJvTBLqILAIWAaSnp3e3VkvSmXDhA65vbxyw/neQv6XbgV5V38SEhu2UhzeeWGjPh6FTu7UfpZTqC64EunSwzLR7/QfgXmNMs0hHmzvfZMwyYBlAVlZW+324ZtAY66c7Ni45MTqlG3Zl5zFdagh0FFsLHA6oLNQhi0opn+RKoOcBQ9u8TgPap2MWsMIZ5onAJSLSZIx5yx1F9lp0ao8C/Ztv9jMdCKs9ZvXd1xRDc4PepUgp5ZNcCfRNwCgRyQTygYXA99puYIzJbHkuIsuB1T4T5mDNWV6R1+23Hc3NBkCaaqG2TC8qUkr5tC6HahhjmoA7sEav7AVeM8bsFpHFIrLY0wW6RXRKj1roNcWHT7yw57e5qEgDXSnle1xpoWOMWQOsabdsaSfb3tT7stwsOtXqLmmsg6DQrrfHOiEaUXccnPeEpiLf+gEd5aKU8kkDYzB1y1Wdla630g8VVzNESnCI8988e771ExAE4YkeKFIppXpngAS6s4ukG90uOcXVJEspDfGjQWzWe+0FEK0XFSmlfJNLXS5+r6WF7kqgr/oJ5G3m3Kp6IgKOEJTwHWisgM0vQHMjDJng2VqVUqqHBkigO1voXY10cTTDtlchfgQFtmTKbAnMnPJDKD8E33xobTP+Go+WqpRSPTUwAj0kEkJjum6hVx0HRxNMW8SvvjyTqJhAZo5yXhQ75VbP16mUUr0wcDqDo9O6DnTn+rLAJPYUVDAuJboPClNKKfcYQIGeAvYuulycFw6tyoEmh+GGacP6oDCllHKPARboXbXQrUD/214Hc8YMJr3lLkVKKeUHBk6gx6RZN3huqu98G3s+xhbCvsogsjLi+q42pZRyg4ET6K6MRbcX0BAxBBAyEyP6pCyllHIXDfS2KvKxBw8G0EBXSvmdgTFsEU5MedsyY2KLj5+C4gPW8+N7KI4+DxFIj9f+c6WUfxlAgZ5sPbYN9IZqeP8RCI2FkGgIi+WLoCxSY8MIDbJ5pUyllOqpgRPoIVEQ0u7iopbnFz8OZ18HwJvPfkJmYlAHO1BKKd82cPrQwXmjizYt9HY3rCivaWDf0UpGDYryQnFKKdU7ftdCb3YYmhyObr0nQIQgW4BzLHrbQHe20GOsybv+9uUR6pscXDtF5ztXSvkfvwv0d3Yd5fa/fdWt9wQIvHDTFC6MToHCHSdWtLTWo6wW+qsbj3D+yETGDNFL/pVS/sfvAn30kEh+dtHobr3n2Q8Osv7r41wYkwbVx62LiwJDrNZ6eAIEhVJR00h+eS03ztDL/ZVS/smlQBeRecDTgA143hjzWLv184FfAw6gCbjLGPOJm2sFYOSgKEZ2s4/74wNFfJFTyuuRDhYAVBZCXIbzhhVW6zynpBqAzMRI9xaslFJ9pMuToiJiA54DLgbGAteLyNh2m70PnG2MmQj8EHjezXX2yuT0OL4+Wsnb2c4FLX3n9oLW8ek5xVWAXlCklPJfroxymQocNMZkG2MagBXA/LYbGGOqjDHG+TICMPiQyenWvCwFJgGAfe8soXrDs1B26EQLvaiaAL2gSCnlx1zpckkFctu8zgOmtd9IRK4EfgcMAr7b0Y5EZBGwCCA9Pb27tfZYVkYc0aGB/ODC8yn/MJLRhaugcJW1MvlsAHJKakiLCyc4cGCN5FRK9R+uBLp0sOyUFrgxZiWwUkQuwOpP/3YH2ywDlgFkZWX1WSs+NjyYbQ/OJSBAqJu6n4ff3sq/dhXy6m3TGTk0jQCsLhftblFK+TNXmqN5wNA2r9OATme4MsZsAEaISGIva3OrgADr36XQsAj+Y/ZEiprCmbtkB89+eJDq+ia+OV7N8CQNdKWU/3Il0DcBo0QkU0SCgYXAqrYbiMhIERHn88lAMFDi7mLdZeSgSP522zSmZsaz/LNDvPrFYWobm7l0Qoq3S1NKqR7rssvFGNMkIncAa7GGLb5ojNktIoud65cCVwM/EJFGoBa4rs1JUp80Y0QiASIsXLaRx9/Zx6T0WM4Zpje1UEr5L/FW7mZlZZnNmzd75bNbGGN4fO0+jpTU8MPzMzXQlVI+T0S2GGOyOlrnd1eKupOIcO+8Md4uQyml3ELH6CmlVD+hga6UUv2EBrpSSvUTGuhKKdVPaKArpVQ/oYGulFL9hAa6Ukr1ExroSinVT3jtSlERKQIO9/DtiUCxG8vxJj0W36TH4pv0WGCYMSapoxVeC/TeEJHNnV366m/0WHyTHotv0mM5Pe1yUUqpfkIDXSml+gl/DfRl3i7AjfRYfJMei2/SYzkNv+xDV0opdSp/baErpZRqRwNdKaX6Cb8LdBGZJyL7ROSgiNzn7Xq6S0QOichOEdkmIpudy+JF5D0ROeB89MlbJ4nIiyJyXER2tVnWae0i8gvn97RPRC7yTtUd6+RYHhaRfOd3s01ELmmzziePRUSGisiHIrJXRHaLyE+dy/3ueznNsfjj9xIqIl+KyHbnsTziXO7Z78UY4zc/WPc0/QYYjnUj6u3AWG/X1c1jOAQktlv2OHCf8/l9wP/zdp2d1H4BMBnY1VXtwFjn9xMCZDq/N5u3j6GLY3kY+O8OtvXZYwGSgcnO51HAfme9fve9nOZY/PF7ESDS+TwI+AKY7unvxd9a6FOBg8aYbGNMA7ACmO/lmtxhPvAX5/O/AFd4r5TOGWM2AKXtFndW+3xghTGm3hiTAxzE+v58QifH0hmfPRZjTKEx5ivn80pgL5CKH34vpzmWzvjysRhjTJXzZZDzx+Dh78XfAj0VyG3zOo/Tf+G+yADvisgWEVnkXDbYGFMI1n/UwCCvVdd9ndXur9/VHSKyw9kl0/LnsF8ci4hkAJOwWoN+/b20Oxbww+9FRGwisg04DrxnjPH49+JvgS4dLPO3cZfnGWMmAxcDt4vIBd4uyEP88btaAowAJgKFwO+dy33+WEQkEngDuMsYYz/dph0s8/Vj8cvvxRjTbIyZCKQBU0XkrNNs7pZj8bdAzwOGtnmdBhR4qZYeMcYUOB+PAyux/qw6JiLJAM7H496rsNs6q93vvitjzDHn/4QO4M+c+JPXp49FRIKwAvBVY8ybzsV++b10dCz++r20MMaUA+uBeXj4e/G3QN8EjBKRTBEJBhYCq7xck8tEJEJEolqeA3OBXVjHcKNzsxuBt71TYY90VvsqYKGIhIhIJjAK+NIL9bms5X80pyuxvhvw4WMREQFeAPYaY55qs8rvvpfOjsVPv5ckEYl1Pg8Dvg18jae/F2+fDe7B2eNLsM5+fwM84O16uln7cKwz2duB3S31AwnA+8AB52O8t2vtpP6/Y/3J24jVorjldLUDDzi/p33Axd6u34Vj+SuwE9jh/B8s2dePBTgf60/zHcA2588l/vi9nOZY/PF7mQBsdda8C3jQudyj34te+q+UUv2Ev3W5KKWU6oQGulJK9RMa6Eop1U9ooCulVD+hga6UUv2EBrpSSvUTGuhKKdVP/H/0W+sNMEJWIgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics[['accuracy','val_accuracy']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b7bfec8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.29155272245407104, 1.0]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(scaled_X_test,y_test,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "885181fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = len(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b8bafef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4d8241fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c52a52ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=4,activation='relu'))\n",
    "\n",
    "# Last layer for multi-class classification of 3 species\n",
    "model.add(Dense(units=3,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a69e56b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1416 - accuracy: 0.3400\n",
      "Epoch 2/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1317 - accuracy: 0.3467\n",
      "Epoch 3/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.1223 - accuracy: 0.3667\n",
      "Epoch 4/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.1120 - accuracy: 0.3733\n",
      "Epoch 5/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1031 - accuracy: 0.4133\n",
      "Epoch 6/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0936 - accuracy: 0.4267\n",
      "Epoch 7/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0845 - accuracy: 0.4200\n",
      "Epoch 8/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0759 - accuracy: 0.4333\n",
      "Epoch 9/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0688 - accuracy: 0.4600\n",
      "Epoch 10/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0604 - accuracy: 0.4600\n",
      "Epoch 11/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0527 - accuracy: 0.4600\n",
      "Epoch 12/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0456 - accuracy: 0.4533\n",
      "Epoch 13/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0386 - accuracy: 0.4467\n",
      "Epoch 14/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0316 - accuracy: 0.4533\n",
      "Epoch 15/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0253 - accuracy: 0.4733\n",
      "Epoch 16/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0187 - accuracy: 0.4733\n",
      "Epoch 17/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0123 - accuracy: 0.4867\n",
      "Epoch 18/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0064 - accuracy: 0.5067\n",
      "Epoch 19/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9997 - accuracy: 0.5333\n",
      "Epoch 20/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9937 - accuracy: 0.5267\n",
      "Epoch 21/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9878 - accuracy: 0.5333\n",
      "Epoch 22/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9815 - accuracy: 0.5200\n",
      "Epoch 23/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9761 - accuracy: 0.5600\n",
      "Epoch 24/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9704 - accuracy: 0.5600\n",
      "Epoch 25/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9649 - accuracy: 0.5667\n",
      "Epoch 26/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9595 - accuracy: 0.5600\n",
      "Epoch 27/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9539 - accuracy: 0.5667\n",
      "Epoch 28/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9489 - accuracy: 0.5667\n",
      "Epoch 29/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9438 - accuracy: 0.5600\n",
      "Epoch 30/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9384 - accuracy: 0.5733\n",
      "Epoch 31/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9335 - accuracy: 0.5733\n",
      "Epoch 32/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9286 - accuracy: 0.5933\n",
      "Epoch 33/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9236 - accuracy: 0.6067\n",
      "Epoch 34/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9188 - accuracy: 0.6133\n",
      "Epoch 35/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9142 - accuracy: 0.6400\n",
      "Epoch 36/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9092 - accuracy: 0.6467\n",
      "Epoch 37/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9044 - accuracy: 0.6667\n",
      "Epoch 38/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8997 - accuracy: 0.6667\n",
      "Epoch 39/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8950 - accuracy: 0.6667\n",
      "Epoch 40/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8904 - accuracy: 0.6667\n",
      "Epoch 41/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8859 - accuracy: 0.6733\n",
      "Epoch 42/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8813 - accuracy: 0.6733\n",
      "Epoch 43/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8766 - accuracy: 0.6733\n",
      "Epoch 44/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8721 - accuracy: 0.6867\n",
      "Epoch 45/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8676 - accuracy: 0.6933\n",
      "Epoch 46/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8632 - accuracy: 0.6933\n",
      "Epoch 47/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8587 - accuracy: 0.6933\n",
      "Epoch 48/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8544 - accuracy: 0.7000\n",
      "Epoch 49/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8498 - accuracy: 0.7000\n",
      "Epoch 50/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8454 - accuracy: 0.7000\n",
      "Epoch 51/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8410 - accuracy: 0.7067\n",
      "Epoch 52/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8366 - accuracy: 0.7000\n",
      "Epoch 53/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.8323 - accuracy: 0.7133\n",
      "Epoch 54/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8279 - accuracy: 0.7133\n",
      "Epoch 55/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8237 - accuracy: 0.7133\n",
      "Epoch 56/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8194 - accuracy: 0.7133\n",
      "Epoch 57/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8150 - accuracy: 0.7200\n",
      "Epoch 58/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8107 - accuracy: 0.7200\n",
      "Epoch 59/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8066 - accuracy: 0.7133\n",
      "Epoch 60/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8023 - accuracy: 0.7067\n",
      "Epoch 61/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7981 - accuracy: 0.7067\n",
      "Epoch 62/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7940 - accuracy: 0.7067\n",
      "Epoch 63/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7898 - accuracy: 0.7200\n",
      "Epoch 64/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7855 - accuracy: 0.7200\n",
      "Epoch 65/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7814 - accuracy: 0.7200\n",
      "Epoch 66/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7771 - accuracy: 0.7200\n",
      "Epoch 67/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7729 - accuracy: 0.7200\n",
      "Epoch 68/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7687 - accuracy: 0.7333\n",
      "Epoch 69/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7646 - accuracy: 0.7333\n",
      "Epoch 70/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7604 - accuracy: 0.7333\n",
      "Epoch 71/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7564 - accuracy: 0.7333\n",
      "Epoch 72/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7521 - accuracy: 0.7333\n",
      "Epoch 73/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7482 - accuracy: 0.7333\n",
      "Epoch 74/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7442 - accuracy: 0.7333\n",
      "Epoch 75/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7398 - accuracy: 0.7333\n",
      "Epoch 76/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7357 - accuracy: 0.7333\n",
      "Epoch 77/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7317 - accuracy: 0.7333\n",
      "Epoch 78/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7275 - accuracy: 0.7333\n",
      "Epoch 79/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7234 - accuracy: 0.7400\n",
      "Epoch 80/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7194 - accuracy: 0.7400\n",
      "Epoch 81/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7153 - accuracy: 0.7400\n",
      "Epoch 82/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7113 - accuracy: 0.7467\n",
      "Epoch 83/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7072 - accuracy: 0.7400\n",
      "Epoch 84/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7032 - accuracy: 0.7400\n",
      "Epoch 85/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6992 - accuracy: 0.7400\n",
      "Epoch 86/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6952 - accuracy: 0.7467\n",
      "Epoch 87/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6914 - accuracy: 0.7400\n",
      "Epoch 88/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6872 - accuracy: 0.7467\n",
      "Epoch 89/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6833 - accuracy: 0.7533\n",
      "Epoch 90/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6796 - accuracy: 0.7600\n",
      "Epoch 91/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6755 - accuracy: 0.7600\n",
      "Epoch 92/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6715 - accuracy: 0.7667\n",
      "Epoch 93/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6677 - accuracy: 0.7667\n",
      "Epoch 94/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6637 - accuracy: 0.7667\n",
      "Epoch 95/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6599 - accuracy: 0.7667\n",
      "Epoch 96/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6558 - accuracy: 0.7667\n",
      "Epoch 97/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6522 - accuracy: 0.7667\n",
      "Epoch 98/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6482 - accuracy: 0.7667\n",
      "Epoch 99/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6446 - accuracy: 0.7867\n",
      "Epoch 100/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6406 - accuracy: 0.7800\n",
      "Epoch 101/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6368 - accuracy: 0.7867\n",
      "Epoch 102/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6329 - accuracy: 0.7867\n",
      "Epoch 103/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6292 - accuracy: 0.7867\n",
      "Epoch 104/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6256 - accuracy: 0.7867\n",
      "Epoch 105/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6218 - accuracy: 0.7933\n",
      "Epoch 106/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6182 - accuracy: 0.7933\n",
      "Epoch 107/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6142 - accuracy: 0.7933\n",
      "Epoch 108/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6107 - accuracy: 0.7933\n",
      "Epoch 109/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6070 - accuracy: 0.7933\n",
      "Epoch 110/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6034 - accuracy: 0.7933\n",
      "Epoch 111/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5999 - accuracy: 0.8000\n",
      "Epoch 112/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5962 - accuracy: 0.8067\n",
      "Epoch 113/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5926 - accuracy: 0.8067\n",
      "Epoch 114/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5893 - accuracy: 0.8067\n",
      "Epoch 115/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5856 - accuracy: 0.8067\n",
      "Epoch 116/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5821 - accuracy: 0.8067\n",
      "Epoch 117/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5786 - accuracy: 0.8133\n",
      "Epoch 118/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5753 - accuracy: 0.8200\n",
      "Epoch 119/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5718 - accuracy: 0.8200\n",
      "Epoch 120/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5685 - accuracy: 0.8333\n",
      "Epoch 121/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5652 - accuracy: 0.8400\n",
      "Epoch 122/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5618 - accuracy: 0.8400\n",
      "Epoch 123/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5588 - accuracy: 0.8400\n",
      "Epoch 124/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5553 - accuracy: 0.8400\n",
      "Epoch 125/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5525 - accuracy: 0.8400\n",
      "Epoch 126/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5489 - accuracy: 0.8400\n",
      "Epoch 127/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5456 - accuracy: 0.8400\n",
      "Epoch 128/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5424 - accuracy: 0.8400\n",
      "Epoch 129/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5393 - accuracy: 0.8400\n",
      "Epoch 130/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5363 - accuracy: 0.8400\n",
      "Epoch 131/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5331 - accuracy: 0.8400\n",
      "Epoch 132/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5302 - accuracy: 0.8467\n",
      "Epoch 133/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5270 - accuracy: 0.8467\n",
      "Epoch 134/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5240 - accuracy: 0.8467\n",
      "Epoch 135/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5209 - accuracy: 0.8467\n",
      "Epoch 136/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5181 - accuracy: 0.8467\n",
      "Epoch 137/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.8467\n",
      "Epoch 138/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.8467\n",
      "Epoch 139/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5093 - accuracy: 0.8467\n",
      "Epoch 140/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.8467\n",
      "Epoch 141/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.8600\n",
      "Epoch 142/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5006 - accuracy: 0.8600\n",
      "Epoch 143/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4977 - accuracy: 0.8600\n",
      "Epoch 144/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4949 - accuracy: 0.8600\n",
      "Epoch 145/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4922 - accuracy: 0.8600\n",
      "Epoch 146/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4893 - accuracy: 0.8600\n",
      "Epoch 147/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4866 - accuracy: 0.8600\n",
      "Epoch 148/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4839 - accuracy: 0.8600\n",
      "Epoch 149/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4812 - accuracy: 0.8667\n",
      "Epoch 150/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.8733\n",
      "Epoch 151/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4758 - accuracy: 0.8800\n",
      "Epoch 152/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4733 - accuracy: 0.8733\n",
      "Epoch 153/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4707 - accuracy: 0.8667\n",
      "Epoch 154/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.8667\n",
      "Epoch 155/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.8733\n",
      "Epoch 156/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.8733\n",
      "Epoch 157/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.8733\n",
      "Epoch 158/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4581 - accuracy: 0.8667\n",
      "Epoch 159/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.8667\n",
      "Epoch 160/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.8733\n",
      "Epoch 161/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.8800\n",
      "Epoch 162/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.8800\n",
      "Epoch 163/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.8867\n",
      "Epoch 164/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.8867\n",
      "Epoch 165/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.8933\n",
      "Epoch 166/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.9000\n",
      "Epoch 167/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.9000\n",
      "Epoch 168/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.9000\n",
      "Epoch 169/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.9000\n",
      "Epoch 170/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.9000\n",
      "Epoch 171/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.9000\n",
      "Epoch 172/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.9000\n",
      "Epoch 173/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.9000\n",
      "Epoch 174/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.9000\n",
      "Epoch 175/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.9000\n",
      "Epoch 176/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4156 - accuracy: 0.9000\n",
      "Epoch 177/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4135 - accuracy: 0.9000\n",
      "Epoch 178/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4113 - accuracy: 0.9000\n",
      "Epoch 179/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4090 - accuracy: 0.9000\n",
      "Epoch 180/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4069 - accuracy: 0.9000\n",
      "Epoch 181/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4047 - accuracy: 0.9000\n",
      "Epoch 182/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4026 - accuracy: 0.9000\n",
      "Epoch 183/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4005 - accuracy: 0.9000\n",
      "Epoch 184/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3984 - accuracy: 0.9000\n",
      "Epoch 185/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3963 - accuracy: 0.9000\n",
      "Epoch 186/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3942 - accuracy: 0.9000\n",
      "Epoch 187/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3921 - accuracy: 0.9000\n",
      "Epoch 188/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3902 - accuracy: 0.9000\n",
      "Epoch 189/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3881 - accuracy: 0.9000\n",
      "Epoch 190/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3860 - accuracy: 0.9000\n",
      "Epoch 191/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3840 - accuracy: 0.9067\n",
      "Epoch 192/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3820 - accuracy: 0.9067\n",
      "Epoch 193/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3800 - accuracy: 0.9067\n",
      "Epoch 194/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3780 - accuracy: 0.9133\n",
      "Epoch 195/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3760 - accuracy: 0.9200\n",
      "Epoch 196/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3741 - accuracy: 0.9200\n",
      "Epoch 197/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3721 - accuracy: 0.9200\n",
      "Epoch 198/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3702 - accuracy: 0.9200\n",
      "Epoch 199/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3682 - accuracy: 0.9200\n",
      "Epoch 200/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3663 - accuracy: 0.9200\n",
      "Epoch 201/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3645 - accuracy: 0.9200\n",
      "Epoch 202/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3627 - accuracy: 0.9333\n",
      "Epoch 203/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3607 - accuracy: 0.9400\n",
      "Epoch 204/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3590 - accuracy: 0.9400\n",
      "Epoch 205/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3569 - accuracy: 0.9533\n",
      "Epoch 206/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3551 - accuracy: 0.9533\n",
      "Epoch 207/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.9600\n",
      "Epoch 208/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3514 - accuracy: 0.9600\n",
      "Epoch 209/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3495 - accuracy: 0.9667\n",
      "Epoch 210/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3477 - accuracy: 0.9667\n",
      "Epoch 211/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3459 - accuracy: 0.9667\n",
      "Epoch 212/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3442 - accuracy: 0.9667\n",
      "Epoch 213/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3424 - accuracy: 0.9667\n",
      "Epoch 214/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3407 - accuracy: 0.9667\n",
      "Epoch 215/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3390 - accuracy: 0.9667\n",
      "Epoch 216/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3370 - accuracy: 0.9667\n",
      "Epoch 217/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3354 - accuracy: 0.9667\n",
      "Epoch 218/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3336 - accuracy: 0.9667\n",
      "Epoch 219/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3319 - accuracy: 0.9667\n",
      "Epoch 220/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.9667\n",
      "Epoch 221/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.9733\n",
      "Epoch 222/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3268 - accuracy: 0.9667\n",
      "Epoch 223/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3250 - accuracy: 0.9800\n",
      "Epoch 224/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3233 - accuracy: 0.9867\n",
      "Epoch 225/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3217 - accuracy: 0.9867\n",
      "Epoch 226/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3200 - accuracy: 0.9867\n",
      "Epoch 227/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3184 - accuracy: 0.9933\n",
      "Epoch 228/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3167 - accuracy: 0.9933\n",
      "Epoch 229/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3150 - accuracy: 0.9933\n",
      "Epoch 230/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3135 - accuracy: 0.9933\n",
      "Epoch 231/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3119 - accuracy: 0.9933\n",
      "Epoch 232/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3102 - accuracy: 0.9933\n",
      "Epoch 233/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3086 - accuracy: 0.9933\n",
      "Epoch 234/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3070 - accuracy: 0.9933\n",
      "Epoch 235/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3054 - accuracy: 0.9933\n",
      "Epoch 236/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3039 - accuracy: 0.9933\n",
      "Epoch 237/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3025 - accuracy: 0.9933\n",
      "Epoch 238/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3008 - accuracy: 0.9933\n",
      "Epoch 239/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2993 - accuracy: 0.9933\n",
      "Epoch 240/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2976 - accuracy: 0.9933\n",
      "Epoch 241/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2962 - accuracy: 0.9933\n",
      "Epoch 242/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2946 - accuracy: 0.9933\n",
      "Epoch 243/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2931 - accuracy: 0.9933\n",
      "Epoch 244/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2916 - accuracy: 0.9933\n",
      "Epoch 245/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2900 - accuracy: 0.9933\n",
      "Epoch 246/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2887 - accuracy: 0.9933\n",
      "Epoch 247/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2872 - accuracy: 0.9933\n",
      "Epoch 248/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2857 - accuracy: 1.0000\n",
      "Epoch 249/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2843 - accuracy: 1.0000\n",
      "Epoch 250/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2827 - accuracy: 1.0000\n",
      "Epoch 251/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2812 - accuracy: 1.0000\n",
      "Epoch 252/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2798 - accuracy: 1.0000\n",
      "Epoch 253/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2784 - accuracy: 1.0000\n",
      "Epoch 254/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2770 - accuracy: 1.0000\n",
      "Epoch 255/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2755 - accuracy: 1.0000\n",
      "Epoch 256/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2740 - accuracy: 1.0000\n",
      "Epoch 257/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2728 - accuracy: 1.0000\n",
      "Epoch 258/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2715 - accuracy: 1.0000\n",
      "Epoch 259/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2699 - accuracy: 1.0000\n",
      "Epoch 260/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2685 - accuracy: 1.0000\n",
      "Epoch 261/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2672 - accuracy: 1.0000\n",
      "Epoch 262/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2657 - accuracy: 1.0000\n",
      "Epoch 263/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2645 - accuracy: 1.0000\n",
      "Epoch 264/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2630 - accuracy: 1.0000\n",
      "Epoch 265/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2617 - accuracy: 1.0000\n",
      "Epoch 266/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2604 - accuracy: 1.0000\n",
      "Epoch 267/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2590 - accuracy: 1.0000\n",
      "Epoch 268/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2578 - accuracy: 1.0000\n",
      "Epoch 269/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2564 - accuracy: 1.0000\n",
      "Epoch 270/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2553 - accuracy: 1.0000\n",
      "Epoch 271/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2537 - accuracy: 1.0000\n",
      "Epoch 272/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2524 - accuracy: 1.0000\n",
      "Epoch 273/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2511 - accuracy: 1.0000\n",
      "Epoch 274/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2498 - accuracy: 1.0000\n",
      "Epoch 275/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2485 - accuracy: 1.0000\n",
      "Epoch 276/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2475 - accuracy: 1.0000\n",
      "Epoch 277/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2460 - accuracy: 1.0000\n",
      "Epoch 278/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 1.0000\n",
      "Epoch 279/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2436 - accuracy: 1.0000\n",
      "Epoch 280/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2422 - accuracy: 1.0000\n",
      "Epoch 281/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2410 - accuracy: 1.0000\n",
      "Epoch 282/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2398 - accuracy: 1.0000\n",
      "Epoch 283/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2386 - accuracy: 1.0000\n",
      "Epoch 284/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2373 - accuracy: 1.0000\n",
      "Epoch 285/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2362 - accuracy: 1.0000\n",
      "Epoch 286/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2349 - accuracy: 1.0000\n",
      "Epoch 287/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2337 - accuracy: 1.0000\n",
      "Epoch 288/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2325 - accuracy: 1.0000\n",
      "Epoch 289/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2313 - accuracy: 1.0000\n",
      "Epoch 290/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2301 - accuracy: 1.0000\n",
      "Epoch 291/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2289 - accuracy: 1.0000\n",
      "Epoch 292/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2277 - accuracy: 1.0000\n",
      "Epoch 293/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2266 - accuracy: 1.0000\n",
      "Epoch 294/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2255 - accuracy: 1.0000\n",
      "Epoch 295/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2243 - accuracy: 1.0000\n",
      "Epoch 296/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2232 - accuracy: 1.0000\n",
      "Epoch 297/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2219 - accuracy: 1.0000\n",
      "Epoch 298/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2208 - accuracy: 1.0000\n",
      "Epoch 299/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2198 - accuracy: 1.0000\n",
      "Epoch 300/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2186 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16739e0abb0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_X,y,epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "762d4003",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"iris_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "06ae832e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6fc8b9f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['iris_scaler.pkl']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(scaler,'iris_scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "734bffe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d5f4f644",
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_model = load_model(\"iris_model.h5\")\n",
    "flower_scaler = joblib.load(\"iris_scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "35b31c51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0   1            5.1           3.5            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ef7cbfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_example = {'sepal_length':5.1,\n",
    "                 'sepal_width':3.5,\n",
    "                 'petal_length':1.4,\n",
    "                 'petal_width':0.2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5e7b2746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_prediction(model,scaler,sample_json):\n",
    "    s_len = sample_json['sepal_length']\n",
    "    s_wid = sample_json['sepal_width']\n",
    "    p_len = sample_json['petal_length']\n",
    "    p_wid = sample_json['petal_width']\n",
    "    \n",
    "    flower = [[s_len,s_wid,p_len,p_wid]]\n",
    "    \n",
    "              \n",
    "    flower = scaler.transform(flower)\n",
    "              \n",
    "    classes = np.array(['setosa', 'versicolor', 'virginica'])\n",
    "    \n",
    "    class_ind = model.predict_classes(flower)\n",
    "    \n",
    "    return classes[class_ind][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b7f48421",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 4 features, but MinMaxScaler is expecting 5 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ADITYA~1\\AppData\\Local\\Temp/ipykernel_9792/1142802719.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mreturn_prediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflower_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mflower_scaler\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mflower_example\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\ADITYA~1\\AppData\\Local\\Temp/ipykernel_9792/684029974.py\u001b[0m in \u001b[0;36mreturn_prediction\u001b[1;34m(model, scaler, sample_json)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mflower\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflower\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'setosa'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'versicolor'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'virginica'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    432\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m         X = self._validate_data(X, copy=self.copy, dtype=FLOAT_DTYPES,\n\u001b[0m\u001b[0;32m    435\u001b[0m                                 force_all_finite=\"allow-nan\", reset=False)\n\u001b[0;32m    436\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ensure_2d'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 437\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 365\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    366\u001b[0m                 \u001b[1;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m                 f\"is expecting {self.n_features_in_} features as input.\")\n",
      "\u001b[1;31mValueError\u001b[0m: X has 4 features, but MinMaxScaler is expecting 5 features as input."
     ]
    }
   ],
   "source": [
    "return_prediction(flower_model,flower_scaler,flower_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dc883dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "\n",
    "\n",
    "flower_model = load_model(\"iris_model.h5\")\n",
    "flower_scaler = joblib.load(\"iris_scaler.pkl\")\n",
    "\n",
    "\n",
    "def return_prediction(model,scaler,sample_json):\n",
    "    \n",
    "    # For larger data features, you should probably write a for loop\n",
    "    # That builds out this array for you\n",
    "    \n",
    "    s_len = sample_json['sepal_length']\n",
    "    s_wid = sample_json['sepal_width']\n",
    "    p_len = sample_json['petal_length']\n",
    "    p_wid = sample_json['petal_width']\n",
    "    \n",
    "    flower = [[s_len,s_wid,p_len,p_wid]]\n",
    "    \n",
    "    flower = scaler.transform(flower)\n",
    "    \n",
    "    classes = np.array(['setosa', 'versicolor', 'virginica'])\n",
    "    \n",
    "    class_ind = model.predict_classes(flower)\n",
    "    \n",
    "    return classes[class_ind][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f311846e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
